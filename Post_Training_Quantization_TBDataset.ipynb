{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook I aim to do the following things:\n",
        "- Train a deep learning model on images of chest X-rays.\n",
        "- Compress the model  using quantization.\n",
        "- Discuss between the compressed and uncompressed models."
      ],
      "metadata": {
        "id": "7QnGxLrJRa1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "I have used the [Tuberculosis (TB) Chest X-ray Database](https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset) from Kaggle.\n",
        "\n",
        "It contains X-ray images of normal and TB infected chest.\n",
        "\n",
        "We will now load the dataset from Kaggle into this colab environment."
      ],
      "metadata": {
        "id": "y6F8ujekRngB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XTkQngrHtskB"
      },
      "outputs": [],
      "source": [
        "!pip -q install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "VX7JdrCXtxzC",
        "outputId": "e2436296-cdb2-459f-c0e0-68992b2bdc3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3a26969-8db7-410d-bed9-01e246348644\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3a26969-8db7-410d-bed9-01e246348644\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"najeebahmadbhuiyan\",\"key\":\"383163a2bb49482a8a9d34b5428d92a4\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "pgApOJCsuHsi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "eG5Klc51uPuQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tawsifurrahman/tuberculosis-tb-chest-xray-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWK8silJuS7y",
        "outputId": "ef8df4b1-fe4c-4af8-9c3d-e20683053cd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tuberculosis-tb-chest-xray-dataset.zip to /content\n",
            " 97% 646M/663M [00:06<00:00, 111MB/s] \n",
            "100% 663M/663M [00:06<00:00, 108MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q tuberculosis-tb-chest-xray-dataset.zip"
      ],
      "metadata": {
        "id": "DkfHoNozuUYh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model\n",
        "\n",
        "Now, we will train the model here. First, we will import the dependencies."
      ],
      "metadata": {
        "id": "dzKuYETsRz2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "HRuVabdwuYbP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "dI_cfbxnucO6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will prepare the dataset for training. We will divide our dataset into training, validation and test set."
      ],
      "metadata": {
        "id": "RoWMRRX2R6W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "PuLFrZaOufgE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = ImageFolder(root=\"/content/TB_Chest_Radiography_Database\", transform=transform)"
      ],
      "metadata": {
        "id": "WLWLUrknuhol"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(full_dataset))\n",
        "val_size = int(0.15 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size]\n",
        ")"
      ],
      "metadata": {
        "id": "5Q0ZSuk4ujHq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "ZdYXw38Luk60"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now create a custom CNN model to train. We can use any other CNN model if we want, but in that case we need to know the model architecture."
      ],
      "metadata": {
        "id": "Bwsp16wzSCqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm4 = nn.BatchNorm2d(256)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool1(self.relu1(self.batch_norm1(self.conv1(x))))\n",
        "        x = self.maxpool2(self.relu2(self.batch_norm2(self.conv2(x))))\n",
        "        x = self.maxpool3(self.relu3(self.batch_norm3(self.conv3(x))))\n",
        "        x = self.maxpool4(self.relu4(self.batch_norm4(self.conv4(x))))\n",
        "        x = self.maxpool5(self.relu5(self.batch_norm5(self.conv5(x))))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "p4726epjumkE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anantaJalil = CustomCNN().to(device)"
      ],
      "metadata": {
        "id": "03EtFwS6upn1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(anantaJalil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AQTVQU2urRA",
        "outputId": "f98238a4-c7f8-4677-8829-e359efcad41c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu4): ReLU()\n",
            "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu5): ReLU()\n",
            "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (dropout2): Dropout(p=0.3, inplace=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=25088, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(anantaJalil.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "p4RoS0gCutnm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created a function `train` to train our model."
      ],
      "metadata": {
        "id": "_y1crxAZSWuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=100, patience=3):\n",
        "    train_losses = []  # To store training losses during each epoch\n",
        "    val_losses = []    # To store validation losses during each epoch\n",
        "    train_accuracies = []  # To store training accuracies during each epoch\n",
        "    val_accuracies = []    # To store validation accuracies during each epoch\n",
        "    train_true_labels = []  # To store true labels during training\n",
        "    train_predicted_labels = []  # To store predicted labels during training\n",
        "    val_true_labels = []  # To store true labels during validation\n",
        "    val_predicted_labels = []  # To store predicted labels during validation\n",
        "    best_val_loss = float('inf')\n",
        "    counter = 0  # Counter for how many epochs the validation loss hasn't improved\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_true_labels_epoch = []\n",
        "        train_predicted_labels_epoch = []\n",
        "\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_true_labels_epoch.extend(labels.cpu().numpy())\n",
        "            train_predicted_labels_epoch.extend(predicted.cpu().numpy())\n",
        "\n",
        "        # Aggregate true and predicted labels for the entire training set\n",
        "        train_true_labels.extend(train_true_labels_epoch)\n",
        "        train_predicted_labels.extend(train_predicted_labels_epoch)\n",
        "\n",
        "        # Calculate training accuracy and loss\n",
        "        train_accuracy = accuracy_score(train_true_labels, train_predicted_labels)\n",
        "        train_loss = criterion(outputs, labels)\n",
        "\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        train_losses.append(train_loss.item())\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_true_labels_epoch = []\n",
        "        val_predicted_labels_epoch = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            total_correct = 0\n",
        "            total_samples = 0\n",
        "            val_loss = 0.0\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_samples += labels.size(0)\n",
        "                total_correct += (predicted == labels).sum().item()\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "                val_true_labels_epoch.extend(labels.cpu().numpy())\n",
        "                val_predicted_labels_epoch.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Aggregate true and predicted labels for the entire validation set\n",
        "            val_true_labels.extend(val_true_labels_epoch)\n",
        "            val_predicted_labels.extend(val_predicted_labels_epoch)\n",
        "\n",
        "            accuracy = total_correct / total_samples\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "            val_accuracies.append(accuracy)\n",
        "            val_losses.append(avg_val_loss)\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {accuracy:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            # Check for improvement in validation loss\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                counter = 0\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "            # Check if early stopping criteria are met\n",
        "            if counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n",
        "                break\n"
      ],
      "metadata": {
        "id": "3GnNPIQauxzS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a function `print_size_of_model` to see the size of it in MB."
      ],
      "metadata": {
        "id": "8unQ71QXSgju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp_delme.pth\")\n",
        "    size_kb = os.path.getsize(\"temp_delme.pth\") / 1e3\n",
        "    size_mb = size_kb / 1e3\n",
        "    print('Size (MB):', size_mb)\n",
        "    os.remove('temp_delme.pth')"
      ],
      "metadata": {
        "id": "gZdYM0FsvGJy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test our function, we create a function called `test`."
      ],
      "metadata": {
        "id": "BXFgENarStWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, device, total_iterations: int = None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_true_labels = []  # To store true labels during testing\n",
        "    test_predicted_labels = []  # To store predicted labels during testing\n",
        "    iterations = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_true_labels.extend(labels.cpu().numpy())\n",
        "            test_predicted_labels.extend(predicted.cpu().numpy())\n",
        "            for idx, i in enumerate(outputs):\n",
        "                if torch.argmax(i) == labels[idx]:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "            iterations += 1\n",
        "            if total_iterations is not None and iterations >= total_iterations:\n",
        "                break\n",
        "    accuracy = accuracy_score(test_true_labels, test_predicted_labels)\n",
        "    print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "fgarmiR8vVFa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will train and save the model. Here, if the model is already trained then it will load the saved model to use."
      ],
      "metadata": {
        "id": "-00ySy_7S0_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FILENAME = 'original_model.pt'"
      ],
      "metadata": {
        "id": "FntMfa4oweQN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Path(MODEL_FILENAME).exists():\n",
        "    anantaJalil.load_state_dict(torch.load(MODEL_FILENAME))\n",
        "    print('Loaded model from disk')\n",
        "else:\n",
        "    train(anantaJalil, train_loader, val_loader, criterion, optimizer, device, num_epochs=100, patience=3)\n",
        "    # Save the model to disk\n",
        "    torch.save(anantaJalil.state_dict(), MODEL_FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnAu3AnpwmqU",
        "outputId": "131d66a7-1f2c-4074-9b16-2a1c6449fea4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 92/92 [11:47<00:00,  7.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Validation Accuracy: 0.9730, Validation Loss: 0.1869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 92/92 [11:45<00:00,  7.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100, Validation Accuracy: 0.9127, Validation Loss: 0.3722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 92/92 [11:55<00:00,  7.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100, Validation Accuracy: 0.9905, Validation Loss: 0.0395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 92/92 [11:44<00:00,  7.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100, Validation Accuracy: 0.9857, Validation Loss: 0.0337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 92/92 [11:43<00:00,  7.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100, Validation Accuracy: 0.9619, Validation Loss: 0.1051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 92/92 [11:38<00:00,  7.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100, Validation Accuracy: 0.9952, Validation Loss: 0.0125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 92/92 [11:37<00:00,  7.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100, Validation Accuracy: 0.9937, Validation Loss: 0.0155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 92/92 [11:39<00:00,  7.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100, Validation Accuracy: 0.9937, Validation Loss: 0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 92/92 [11:37<00:00,  7.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100, Validation Accuracy: 0.9841, Validation Loss: 0.0869\n",
            "Early stopping at epoch 9 due to no improvement in validation loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training is done."
      ],
      "metadata": {
        "id": "aFNfGHbFTHmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing & Seeing the Model Size"
      ],
      "metadata": {
        "id": "df2GV8U-Ub9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now see the weights of the first convolutional layer of the model after training. Also we will see the data type of the weights."
      ],
      "metadata": {
        "id": "N9nVdFUMUoR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the weights matrix of the model before quantization\n",
        "print('Weights before quantization')\n",
        "print(anantaJalil.conv1.weight)\n",
        "print(anantaJalil.conv1.weight.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKM5HUcKPI0A",
        "outputId": "da9dc2b7-89df-47dc-86dc-7e4564afc38a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights before quantization\n",
            "Parameter containing:\n",
            "tensor([[[[-1.4485e-01, -1.3680e-01,  1.4645e-01],\n",
            "          [-3.4057e-02,  4.0066e-02,  1.4653e-01],\n",
            "          [-3.9360e-02, -3.1954e-02,  1.9848e-01]],\n",
            "\n",
            "         [[-4.3736e-02, -5.3364e-02, -7.6015e-02],\n",
            "          [-1.1375e-02, -9.7157e-02,  3.7182e-02],\n",
            "          [-2.4842e-02, -1.9482e-02,  1.8802e-01]],\n",
            "\n",
            "         [[-1.3220e-01,  4.8379e-02,  6.2325e-02],\n",
            "          [ 3.2245e-02, -1.4307e-01, -9.6930e-02],\n",
            "          [-4.3221e-02,  1.1859e-01, -1.1901e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6476e-02,  2.8481e-02, -1.4417e-01],\n",
            "          [ 1.6459e-01, -4.2325e-03, -5.4186e-02],\n",
            "          [ 1.9815e-02, -3.2094e-02,  1.5083e-01]],\n",
            "\n",
            "         [[ 1.8349e-01, -1.1144e-01, -1.6888e-01],\n",
            "          [-4.6052e-02, -1.5621e-01,  5.9176e-02],\n",
            "          [ 1.5712e-01, -1.4579e-02,  5.5457e-02]],\n",
            "\n",
            "         [[-8.7788e-03, -3.6236e-02,  2.2953e-02],\n",
            "          [ 1.8419e-01, -1.1851e-02,  9.2437e-02],\n",
            "          [-1.8030e-01,  5.1614e-02, -1.5324e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2613e-01, -3.3005e-02, -8.1910e-02],\n",
            "          [ 1.4338e-01, -2.5556e-02,  4.4361e-02],\n",
            "          [-1.5235e-02, -1.8513e-01, -6.9536e-02]],\n",
            "\n",
            "         [[ 1.5507e-01, -1.6935e-01,  3.4482e-03],\n",
            "          [ 1.2493e-01, -1.2673e-01, -2.5969e-02],\n",
            "          [ 8.1320e-02,  6.6221e-02,  1.4886e-01]],\n",
            "\n",
            "         [[-1.3599e-01,  7.7980e-02,  3.2938e-02],\n",
            "          [-1.4949e-02,  9.8223e-02,  3.5851e-02],\n",
            "          [ 1.1748e-01, -2.6009e-02, -1.5931e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0583e-02,  1.3259e-01,  7.6627e-02],\n",
            "          [-1.7558e-01, -1.6236e-01,  2.1227e-02],\n",
            "          [-1.6846e-01, -1.5338e-01, -9.5833e-02]],\n",
            "\n",
            "         [[-5.7477e-02, -9.9511e-02,  1.2672e-01],\n",
            "          [-7.4501e-02, -5.3230e-02,  3.6593e-02],\n",
            "          [-7.9914e-02, -2.5290e-02,  1.7934e-01]],\n",
            "\n",
            "         [[ 3.0984e-02,  1.6819e-01, -1.9126e-01],\n",
            "          [-8.7600e-03,  1.7447e-01,  1.5938e-01],\n",
            "          [-3.7053e-02, -1.5508e-01, -1.2381e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.9472e-02, -9.3301e-02, -1.7153e-01],\n",
            "          [-2.0297e-02, -1.4636e-01,  3.3298e-02],\n",
            "          [ 1.8910e-01,  1.6683e-01,  7.0740e-03]],\n",
            "\n",
            "         [[-8.9702e-02, -5.7498e-02, -9.6235e-02],\n",
            "          [-1.2082e-01, -4.8384e-02, -1.5011e-01],\n",
            "          [-1.6119e-01,  1.3172e-01, -1.4941e-01]],\n",
            "\n",
            "         [[-3.7335e-02, -7.5899e-02, -6.7303e-02],\n",
            "          [ 4.6689e-02, -3.8075e-02,  8.0344e-02],\n",
            "          [ 1.5727e-01, -1.6785e-01, -5.0822e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6822e-01,  7.5057e-02,  2.5015e-02],\n",
            "          [-1.2289e-01,  4.1975e-02,  9.0186e-02],\n",
            "          [-4.6694e-02, -7.4410e-02, -2.6818e-02]],\n",
            "\n",
            "         [[-5.3251e-02,  4.3260e-02,  1.9090e-01],\n",
            "          [-5.9722e-02, -7.2373e-02,  5.3751e-02],\n",
            "          [-1.4732e-01, -3.5794e-02,  9.1206e-02]],\n",
            "\n",
            "         [[-6.6974e-02,  6.0085e-02, -1.7008e-01],\n",
            "          [-6.8811e-02,  9.5998e-02,  3.0285e-02],\n",
            "          [ 1.1319e-02, -1.1347e-01, -7.5955e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9287e-01,  1.3447e-01,  3.9816e-02],\n",
            "          [-1.4233e-01,  1.6953e-02, -9.6035e-02],\n",
            "          [ 3.6781e-02,  5.9506e-02,  1.1930e-01]],\n",
            "\n",
            "         [[ 1.4667e-01,  4.3919e-02,  1.4326e-01],\n",
            "          [-8.8140e-02,  5.6622e-02,  1.0691e-01],\n",
            "          [ 1.3256e-01, -1.2601e-01,  1.3004e-01]],\n",
            "\n",
            "         [[-5.3154e-02, -2.7076e-02, -7.9651e-02],\n",
            "          [-1.8565e-01,  1.3548e-02, -1.6880e-01],\n",
            "          [ 2.9835e-02, -3.5791e-02,  2.5176e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4619e-01, -4.5575e-02, -1.3228e-01],\n",
            "          [-3.9495e-02, -1.8305e-02, -1.3342e-01],\n",
            "          [ 9.5899e-03, -2.5378e-02,  1.9978e-02]],\n",
            "\n",
            "         [[-5.5488e-03,  1.4521e-02,  1.2180e-01],\n",
            "          [-4.7447e-02,  1.7493e-01,  9.3101e-02],\n",
            "          [ 7.4086e-02,  1.4242e-01,  1.7132e-02]],\n",
            "\n",
            "         [[ 6.2495e-03, -1.7456e-01,  3.8641e-02],\n",
            "          [ 8.3534e-02, -1.7961e-01, -4.6430e-02],\n",
            "          [-6.7593e-02, -8.0758e-02,  1.3607e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.2535e-01,  1.5905e-01, -2.0422e-02],\n",
            "          [-1.8040e-01, -1.6615e-01,  1.1564e-01],\n",
            "          [ 1.5439e-01,  1.2831e-01,  1.1382e-01]],\n",
            "\n",
            "         [[ 1.4497e-01, -1.1162e-01, -4.4659e-02],\n",
            "          [ 1.4535e-01, -1.0308e-01, -1.5973e-02],\n",
            "          [ 1.6951e-01,  1.0802e-01, -2.8194e-03]],\n",
            "\n",
            "         [[ 4.1831e-02, -1.9410e-01, -1.5654e-01],\n",
            "          [ 9.9299e-02,  1.0513e-01,  2.0982e-02],\n",
            "          [ 1.2772e-01, -1.2188e-01, -4.2360e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8148e-01, -1.7077e-01,  1.2820e-01],\n",
            "          [-5.2389e-02,  7.4325e-02, -7.3267e-02],\n",
            "          [-2.3649e-02, -1.3725e-01, -1.4007e-01]],\n",
            "\n",
            "         [[ 8.3448e-02,  5.1999e-03,  1.0136e-01],\n",
            "          [-1.2541e-02,  1.1321e-01, -1.6334e-01],\n",
            "          [ 1.5902e-01,  1.9641e-01, -8.2208e-02]],\n",
            "\n",
            "         [[ 1.7930e-01,  2.2610e-01,  1.7081e-01],\n",
            "          [-2.5071e-02,  1.5448e-01,  6.8007e-02],\n",
            "          [-8.5555e-02, -1.1930e-01,  1.0719e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2714e-01, -1.7917e-01, -5.1065e-02],\n",
            "          [-1.6687e-01,  1.0116e-01, -5.0133e-02],\n",
            "          [ 1.0480e-01,  1.4754e-01, -3.0409e-02]],\n",
            "\n",
            "         [[-1.7671e-01,  1.3063e-01,  1.7858e-01],\n",
            "          [-7.5116e-02, -3.0969e-02, -1.7836e-02],\n",
            "          [ 6.7601e-02, -1.2187e-01,  9.0318e-02]],\n",
            "\n",
            "         [[-1.3102e-01, -1.2584e-01, -1.5889e-02],\n",
            "          [ 4.2682e-02,  3.6044e-02, -5.7148e-02],\n",
            "          [ 9.7968e-02,  4.6878e-02, -4.7948e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1628e-02,  1.2020e-01, -1.0686e-01],\n",
            "          [-9.2195e-02,  9.9905e-02,  1.6750e-01],\n",
            "          [ 6.2088e-02, -1.6510e-01,  1.3683e-02]],\n",
            "\n",
            "         [[-1.4993e-01,  5.3325e-03, -5.1759e-02],\n",
            "          [-1.7332e-01,  1.7692e-01,  1.3799e-01],\n",
            "          [ 3.8602e-02, -1.5619e-01,  5.3193e-03]],\n",
            "\n",
            "         [[-1.9360e-02,  1.9435e-02, -9.6184e-02],\n",
            "          [ 9.9001e-02, -1.0659e-01,  7.6359e-02],\n",
            "          [ 7.8005e-02, -1.2433e-02,  8.2324e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.8524e-02,  1.6077e-01, -1.4418e-01],\n",
            "          [-1.3015e-01, -5.2862e-02, -1.7723e-01],\n",
            "          [ 1.4648e-01,  1.3033e-01,  1.3013e-01]],\n",
            "\n",
            "         [[ 1.5112e-01,  9.9898e-03, -3.0170e-02],\n",
            "          [ 6.2113e-02,  1.4824e-01,  1.1992e-01],\n",
            "          [ 9.4598e-02, -8.5051e-02, -7.7513e-02]],\n",
            "\n",
            "         [[ 1.7257e-01, -1.4591e-01,  6.8492e-02],\n",
            "          [ 7.6674e-02,  1.4047e-01,  3.9104e-03],\n",
            "          [ 1.3672e-03, -1.4110e-01, -1.9417e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6638e-01, -1.0047e-01, -1.4973e-01],\n",
            "          [ 7.0262e-03, -1.6965e-01, -5.1625e-03],\n",
            "          [ 4.8121e-02, -1.3770e-01,  5.6439e-02]],\n",
            "\n",
            "         [[ 1.5952e-01, -1.5855e-01, -1.2996e-02],\n",
            "          [ 1.1018e-01,  1.2900e-01,  3.3385e-02],\n",
            "          [ 5.9115e-02,  7.5592e-03, -4.6909e-02]],\n",
            "\n",
            "         [[ 9.8112e-02, -5.8003e-02, -3.3492e-02],\n",
            "          [-1.6488e-01, -1.5715e-01,  8.8754e-02],\n",
            "          [ 8.5584e-02,  1.0991e-02,  1.4880e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.5029e-01,  1.9386e-02, -2.3835e-02],\n",
            "          [-1.5252e-01, -1.1194e-01, -1.7367e-01],\n",
            "          [ 1.7158e-01,  8.2248e-02,  1.3868e-01]],\n",
            "\n",
            "         [[-7.7342e-02, -1.1968e-01,  7.2613e-02],\n",
            "          [ 9.6840e-02,  8.9065e-02, -1.0274e-01],\n",
            "          [-3.9820e-02, -1.2344e-01, -1.6468e-01]],\n",
            "\n",
            "         [[ 4.6465e-02,  4.9369e-02, -4.9363e-02],\n",
            "          [ 6.8033e-02, -1.9082e-01,  8.8267e-02],\n",
            "          [-1.7230e-01, -3.7471e-03, -1.1836e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7500e-01,  1.2124e-01, -4.8858e-02],\n",
            "          [ 7.9623e-02,  1.1132e-01, -4.6138e-02],\n",
            "          [ 6.1731e-02, -1.2755e-02,  4.2113e-02]],\n",
            "\n",
            "         [[-1.0926e-01, -6.1210e-02, -1.9513e-01],\n",
            "          [ 1.7577e-01,  8.3555e-03,  8.6979e-02],\n",
            "          [-6.7091e-02,  1.3221e-01,  5.2917e-02]],\n",
            "\n",
            "         [[-2.8143e-02, -1.5441e-01, -3.5441e-03],\n",
            "          [ 1.3865e-01,  1.0547e-01, -1.6358e-01],\n",
            "          [-1.0678e-01, -1.8348e-01, -1.7093e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.4179e-02, -1.8018e-01, -9.7029e-02],\n",
            "          [-2.7487e-02, -6.5842e-02, -1.3170e-01],\n",
            "          [ 1.7317e-03,  7.8886e-02,  1.6478e-01]],\n",
            "\n",
            "         [[-3.9105e-02,  5.8046e-02,  2.2022e-02],\n",
            "          [ 1.4327e-01,  1.7895e-01,  7.4480e-03],\n",
            "          [-1.1772e-02,  9.3387e-02,  3.5594e-02]],\n",
            "\n",
            "         [[ 5.3443e-02,  9.8434e-02, -8.2614e-02],\n",
            "          [ 1.1791e-01, -1.4426e-01, -1.1112e-01],\n",
            "          [ 1.2976e-01, -5.6816e-02, -1.3488e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4422e-02, -1.3135e-01,  1.2964e-01],\n",
            "          [-5.6866e-02, -1.3596e-01, -8.8367e-02],\n",
            "          [ 8.8900e-03, -9.2596e-04,  1.5064e-01]],\n",
            "\n",
            "         [[ 6.8310e-02, -1.6290e-01, -4.8224e-02],\n",
            "          [-2.9538e-02,  1.2949e-01, -6.9709e-03],\n",
            "          [ 8.8054e-02, -1.7063e-01,  8.7938e-02]],\n",
            "\n",
            "         [[-2.1454e-03,  5.6964e-02,  5.6173e-02],\n",
            "          [-7.6995e-02, -1.5185e-01,  4.1270e-02],\n",
            "          [ 4.4791e-02, -2.0197e-01, -5.8808e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.3803e-02,  6.8878e-02, -1.9296e-01],\n",
            "          [-3.8059e-02,  1.3979e-01, -2.0515e-01],\n",
            "          [-8.1235e-02,  1.4063e-01,  1.2339e-01]],\n",
            "\n",
            "         [[ 1.8241e-01,  1.7051e-01, -1.4761e-01],\n",
            "          [ 1.6360e-01,  4.6031e-02, -1.9300e-01],\n",
            "          [ 1.8144e-01,  1.0320e-01,  6.3270e-02]],\n",
            "\n",
            "         [[-1.6577e-01, -2.0389e-01, -1.8418e-01],\n",
            "          [ 1.5598e-01,  2.3414e-02,  6.4942e-02],\n",
            "          [-8.8944e-03,  1.5898e-01, -5.0591e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.1817e-02, -9.5064e-02,  1.1920e-01],\n",
            "          [ 1.5451e-01, -1.4219e-01,  2.8562e-03],\n",
            "          [ 1.5059e-02, -1.5397e-01,  1.8882e-01]],\n",
            "\n",
            "         [[-1.0240e-01, -8.1835e-02, -1.6218e-01],\n",
            "          [-7.4627e-02, -1.6007e-01, -7.3918e-02],\n",
            "          [-1.4906e-01, -1.8383e-01,  8.6605e-02]],\n",
            "\n",
            "         [[-1.3993e-02,  9.4336e-02, -1.4924e-01],\n",
            "          [-1.4341e-01, -3.8623e-02, -2.1781e-02],\n",
            "          [-1.5374e-02, -7.8441e-03,  1.2155e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.3907e-01, -1.5740e-01,  4.5004e-02],\n",
            "          [-1.2888e-01,  1.6407e-01, -2.9501e-03],\n",
            "          [ 1.8381e-01,  1.7150e-01, -6.4922e-02]],\n",
            "\n",
            "         [[ 1.1789e-01, -9.9940e-02,  3.8157e-02],\n",
            "          [ 8.9214e-02, -7.8909e-02, -4.4064e-02],\n",
            "          [-3.5435e-02,  1.1716e-01, -5.1527e-02]],\n",
            "\n",
            "         [[-4.7707e-02, -1.3894e-01,  2.4521e-03],\n",
            "          [ 7.7687e-02, -1.7981e-01,  9.3259e-02],\n",
            "          [ 1.1106e-01,  1.0018e-01, -1.4732e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7184e-01,  8.7111e-02,  1.3187e-01],\n",
            "          [ 1.0801e-01,  9.2048e-02,  5.1726e-02],\n",
            "          [-3.2899e-02,  6.7387e-02, -2.6318e-02]],\n",
            "\n",
            "         [[ 2.3738e-02,  2.4617e-02, -5.0355e-02],\n",
            "          [-1.9379e-01, -6.2319e-02, -1.1678e-02],\n",
            "          [ 1.5735e-01, -9.5129e-02,  1.3452e-01]],\n",
            "\n",
            "         [[ 9.6816e-02,  3.1521e-02, -5.1935e-02],\n",
            "          [ 6.5460e-02, -9.8199e-02,  9.8186e-02],\n",
            "          [-9.4613e-02, -1.3513e-01,  1.9804e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9848e-02,  4.3293e-02,  1.4697e-01],\n",
            "          [-4.2260e-02, -2.2760e-02, -8.0040e-02],\n",
            "          [-6.4313e-02,  9.9457e-02, -1.5328e-02]],\n",
            "\n",
            "         [[-8.6401e-02,  1.2122e-01, -4.2462e-02],\n",
            "          [-4.6077e-02,  4.5522e-03, -1.8964e-01],\n",
            "          [ 1.7582e-01, -8.0537e-02,  1.0792e-01]],\n",
            "\n",
            "         [[ 4.3425e-02, -1.2915e-02,  7.4022e-02],\n",
            "          [-1.6969e-01, -1.1812e-01, -5.4931e-02],\n",
            "          [-1.2871e-01,  2.0057e-02,  1.2578e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9010e-01, -1.3011e-01,  1.5723e-02],\n",
            "          [ 1.6436e-01, -9.5573e-02, -3.6419e-02],\n",
            "          [-7.6545e-02, -1.5593e-01,  1.3378e-01]],\n",
            "\n",
            "         [[ 1.6735e-01, -9.4997e-02, -1.5566e-01],\n",
            "          [-3.6082e-02, -2.1546e-02,  7.4088e-02],\n",
            "          [-2.2543e-03,  3.9237e-02,  1.4824e-01]],\n",
            "\n",
            "         [[-1.4179e-01, -1.6659e-01, -4.7469e-02],\n",
            "          [ 8.9369e-02, -6.9953e-02,  1.6150e-01],\n",
            "          [ 5.0271e-02,  9.2768e-02,  1.1813e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4923e-01, -5.4112e-02,  1.0658e-01],\n",
            "          [-5.1818e-02, -3.1535e-02, -8.4230e-02],\n",
            "          [ 1.8770e-01, -8.5369e-02, -1.3622e-01]],\n",
            "\n",
            "         [[ 1.1575e-01,  3.6279e-02, -4.7278e-02],\n",
            "          [ 1.8044e-01, -2.6467e-02, -1.2014e-01],\n",
            "          [ 8.0620e-03, -1.1511e-02,  1.6318e-02]],\n",
            "\n",
            "         [[ 1.3416e-01,  1.7629e-01,  5.4557e-03],\n",
            "          [ 1.5314e-01, -1.4113e-01, -2.6760e-02],\n",
            "          [-2.5497e-02, -2.4365e-02, -1.0302e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.7513e-02,  3.8575e-02,  1.0656e-01],\n",
            "          [-4.2221e-02,  1.8947e-01, -7.0441e-02],\n",
            "          [-2.9824e-02, -2.0148e-02, -1.0547e-01]],\n",
            "\n",
            "         [[ 1.7514e-01,  1.9166e-01,  1.2173e-02],\n",
            "          [-1.2226e-02,  1.3446e-01, -1.0550e-01],\n",
            "          [-4.3547e-03,  1.1703e-01, -1.0803e-01]],\n",
            "\n",
            "         [[ 1.1865e-01,  1.0765e-01,  1.1505e-01],\n",
            "          [-4.4685e-02, -2.4972e-02,  1.7249e-02],\n",
            "          [ 1.1991e-01,  8.3728e-02,  1.5415e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6383e-02, -4.6928e-02,  1.7191e-01],\n",
            "          [ 1.5468e-01, -2.4082e-02,  1.0338e-02],\n",
            "          [ 7.5416e-02,  3.8180e-02, -1.9415e-01]],\n",
            "\n",
            "         [[-3.4266e-02,  1.1816e-02, -3.6417e-02],\n",
            "          [ 2.3780e-02, -4.2697e-02,  1.0335e-01],\n",
            "          [-1.2595e-02, -1.4068e-01,  2.9151e-02]],\n",
            "\n",
            "         [[-7.8301e-02,  8.1336e-02,  1.5198e-01],\n",
            "          [-8.0917e-02,  2.7422e-02, -8.9801e-02],\n",
            "          [ 2.0528e-02, -1.2649e-01, -4.3358e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1826e-01, -1.8517e-01, -1.2369e-01],\n",
            "          [ 1.8030e-01,  2.2952e-02,  1.5220e-01],\n",
            "          [-1.4264e-02, -1.0658e-01, -1.5433e-01]],\n",
            "\n",
            "         [[-1.7429e-01, -9.8733e-02,  3.4893e-02],\n",
            "          [ 7.0552e-02, -4.7045e-02, -1.7623e-01],\n",
            "          [ 1.4588e-01, -1.4324e-01,  8.4266e-02]],\n",
            "\n",
            "         [[ 5.5731e-03,  1.3650e-01,  1.9102e-01],\n",
            "          [ 1.7546e-01,  7.6116e-02,  1.2114e-01],\n",
            "          [-1.2064e-01,  9.7246e-03,  1.8688e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.5208e-02,  1.1376e-01,  9.9147e-02],\n",
            "          [-1.3112e-01,  1.7266e-01,  1.4257e-01],\n",
            "          [-1.5019e-01, -9.5405e-02, -7.1847e-02]],\n",
            "\n",
            "         [[ 2.9326e-02, -8.3908e-02, -9.7278e-02],\n",
            "          [-2.0065e-02,  1.5652e-02, -1.5911e-02],\n",
            "          [-1.0470e-01,  1.9761e-01, -1.8475e-01]],\n",
            "\n",
            "         [[ 7.5689e-02, -3.2021e-02,  8.3734e-02],\n",
            "          [-1.1155e-01, -6.5183e-02,  1.5887e-01],\n",
            "          [ 1.7209e-01,  1.1356e-01, -1.6012e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2413e-01, -1.6664e-01, -8.7784e-02],\n",
            "          [-4.6882e-02,  1.8333e-01, -8.9443e-02],\n",
            "          [ 8.5285e-03, -9.1295e-02,  8.9521e-02]],\n",
            "\n",
            "         [[-1.0026e-01, -1.6642e-01,  1.4948e-01],\n",
            "          [-1.1051e-01,  1.2226e-01,  9.9898e-02],\n",
            "          [ 8.9069e-02, -5.6319e-02,  1.8739e-01]],\n",
            "\n",
            "         [[ 1.5803e-01, -6.7815e-02,  1.4958e-01],\n",
            "          [-1.5273e-01,  4.9499e-02,  4.0154e-02],\n",
            "          [-9.4899e-02, -1.3024e-01, -3.9622e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7262e-01, -3.1516e-02,  8.1172e-02],\n",
            "          [-8.1405e-02, -9.6629e-02,  1.2381e-01],\n",
            "          [ 4.4744e-02, -1.4893e-01,  4.0342e-02]],\n",
            "\n",
            "         [[ 2.7545e-02,  1.9855e-01, -9.5450e-02],\n",
            "          [ 1.1038e-01,  4.4149e-02, -1.3244e-02],\n",
            "          [-1.7253e-02,  1.1431e-01, -6.4435e-02]],\n",
            "\n",
            "         [[-5.4794e-02,  2.0168e-01,  2.7400e-02],\n",
            "          [ 1.4295e-01, -1.4336e-01,  9.3635e-02],\n",
            "          [-3.6302e-02,  5.7583e-02, -9.9474e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.1058e-01,  1.1961e-01,  9.4726e-02],\n",
            "          [-3.8370e-02,  9.7232e-02, -1.8448e-01],\n",
            "          [ 1.1827e-01,  1.8993e-01, -1.4127e-01]],\n",
            "\n",
            "         [[ 9.7388e-02, -1.9692e-01,  1.6959e-02],\n",
            "          [ 5.8086e-02, -9.9747e-02, -1.0914e-01],\n",
            "          [-1.3209e-01,  6.9679e-02,  9.1267e-02]],\n",
            "\n",
            "         [[ 1.7849e-02, -1.7060e-01,  1.5654e-01],\n",
            "          [-1.4108e-01,  4.9143e-02,  7.8021e-02],\n",
            "          [-2.9095e-02,  8.7397e-03, -1.0404e-01]]]], requires_grad=True)\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, the weights are all float32. We will later quantize it to int8 and it will reduce the overall size of the model without affecting it's accuracy."
      ],
      "metadata": {
        "id": "0NqVh6zDTUhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of the model before quantization')\n",
        "print_size_of_model(anantaJalil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TT_0RhcPEcX",
        "outputId": "17931f2f-f5b3-4a29-9701-d43935fc81fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model before quantization\n",
            "Size (MB): 31.995810000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we see, the original model `anantaJalil` is 31.99MB. Let's test the model and see its performance."
      ],
      "metadata": {
        "id": "nr-VRB0UTkG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(anantaJalil, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epv1gFMBOna_",
        "outputId": "591de6d9-b197-4ce8-d5a5-93ac678c8a51"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [01:07<00:00,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9841269841269841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantizing the Model\n",
        "\n",
        "We will be quantizing our model now in some steps."
      ],
      "metadata": {
        "id": "fanXhwugUsGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert min-max observers in the model\n",
        "\n",
        "We create `QuantizedCustomCNN` which the same as `CustomCNN` with min-max obersevers into it."
      ],
      "metadata": {
        "id": "NoabGwnjU45f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantizedCustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantizedCustomCNN, self).__init__()\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub() # 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm4 = nn.BatchNorm2d(256)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "        self.dequant = torch.quantization.DeQuantStub() # 2\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x) # 1\n",
        "        x = self.maxpool1(self.relu1(self.batch_norm1(self.conv1(x))))\n",
        "        x = self.maxpool2(self.relu2(self.batch_norm2(self.conv2(x))))\n",
        "        x = self.maxpool3(self.relu3(self.batch_norm3(self.conv3(x))))\n",
        "        x = self.maxpool4(self.relu4(self.batch_norm4(self.conv4(x))))\n",
        "        x = self.maxpool5(self.relu5(self.batch_norm5(self.conv5(x))))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dequant(x) # 2\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "RG99R76YOsDt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anantaJalilJr = QuantizedCustomCNN().to(device)\n",
        "# Copy weights from unquantized model\n",
        "anantaJalilJr.load_state_dict(anantaJalil.state_dict())\n",
        "anantaJalilJr.eval()\n",
        "\n",
        "anantaJalilJr.qconfig = torch.ao.quantization.default_qconfig\n",
        "anantaJalilJr = torch.ao.quantization.prepare(anantaJalilJr) # Insert observers\n",
        "anantaJalilJr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuK-gwlYP3kl",
        "outputId": "0dbb8811-bc66-4f7c-e0f7-b6d297ad74a4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedCustomCNN(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (conv1): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (batch_norm1): BatchNorm2d(\n",
              "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu1): ReLU()\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(\n",
              "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (batch_norm2): BatchNorm2d(\n",
              "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(\n",
              "    64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (batch_norm3): BatchNorm2d(\n",
              "    128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu3): ReLU()\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(\n",
              "    128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (batch_norm4): BatchNorm2d(\n",
              "    256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu4): ReLU()\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(\n",
              "    256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (batch_norm5): BatchNorm2d(\n",
              "    512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu5): ReLU()\n",
              "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout1): Dropout(p=0.3, inplace=False)\n",
              "  (dropout2): Dropout(p=0.3, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(\n",
              "    in_features=25088, out_features=256, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (fc2): Linear(\n",
              "    in_features=256, out_features=2, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we see the min-max obeserver inside the model which is important in post-training quantization."
      ],
      "metadata": {
        "id": "GLDkf9VfVV5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(anantaJalilJr, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKJ_Mz0BQJvp",
        "outputId": "24253f4f-a789-43ef-cabd-97b481e519bd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [01:17<00:00,  3.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9841269841269841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calibrating the Model using Test Set"
      ],
      "metadata": {
        "id": "DLSXi80nVjcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "anantaJalilJr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJKxodn7QQMH",
        "outputId": "6f7127ea-c3a2-4ba9-bf53-dbf674c02cd6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedCustomCNN(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=-2.1179039478302, max_val=2.640000104904175)\n",
              "  )\n",
              "  (conv1): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-3.366504669189453, max_val=3.813620090484619)\n",
              "  )\n",
              "  (batch_norm1): BatchNorm2d(\n",
              "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-19.95576286315918, max_val=21.162017822265625)\n",
              "  )\n",
              "  (relu1): ReLU()\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(\n",
              "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-8.581221580505371, max_val=11.276447296142578)\n",
              "  )\n",
              "  (batch_norm2): BatchNorm2d(\n",
              "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-16.42884063720703, max_val=29.13784408569336)\n",
              "  )\n",
              "  (relu2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(\n",
              "    64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-26.302047729492188, max_val=30.289791107177734)\n",
              "  )\n",
              "  (batch_norm3): BatchNorm2d(\n",
              "    128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-23.943239212036133, max_val=29.731801986694336)\n",
              "  )\n",
              "  (relu3): ReLU()\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(\n",
              "    128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-59.802818298339844, max_val=48.9655647277832)\n",
              "  )\n",
              "  (batch_norm4): BatchNorm2d(\n",
              "    256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-24.29132652282715, max_val=29.590429306030273)\n",
              "  )\n",
              "  (relu4): ReLU()\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(\n",
              "    256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-101.13184356689453, max_val=94.79261779785156)\n",
              "  )\n",
              "  (batch_norm5): BatchNorm2d(\n",
              "    512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-20.185190200805664, max_val=22.404144287109375)\n",
              "  )\n",
              "  (relu5): ReLU()\n",
              "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout1): Dropout(p=0.3, inplace=False)\n",
              "  (dropout2): Dropout(p=0.3, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(\n",
              "    in_features=25088, out_features=256, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-257.9188537597656, max_val=153.71546936035156)\n",
              "  )\n",
              "  (fc2): Linear(\n",
              "    in_features=256, out_features=2, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-39.73269271850586, max_val=56.03213882446289)\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantize the Model Using the Collected Statistics\n",
        "\n",
        "By inserting min-max observer, we got the min-max values while calibrating using the test set. Now we will quantize it.\n"
      ],
      "metadata": {
        "id": "XKXIztkyVxoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anantaJalilJr = torch.ao.quantization.convert(anantaJalilJr)"
      ],
      "metadata": {
        "id": "f85MttwXQsLr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "anantaJalilJr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zshdHQ3Qzaa",
        "outputId": "b74d8635-7bba-4124-eae9-90c352baeefb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedCustomCNN(\n",
              "  (quant): Quantize(scale=tensor([0.0375]), zero_point=tensor([57]), dtype=torch.quint8)\n",
              "  (conv1): QuantizedConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.056536413729190826, zero_point=60, padding=(1, 1))\n",
              "  (batch_norm1): QuantizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): QuantizedConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.15635959804058075, zero_point=55, padding=(1, 1))\n",
              "  (batch_norm2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.4456050395965576, zero_point=59, padding=(1, 1))\n",
              "  (batch_norm3): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu3): ReLU()\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.8564440011978149, zero_point=70, padding=(1, 1))\n",
              "  (batch_norm4): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu4): ReLU()\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.5427123308181763, zero_point=66, padding=(1, 1))\n",
              "  (batch_norm5): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu5): ReLU()\n",
              "  (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout1): QuantizedDropout(p=0.3, inplace=False)\n",
              "  (dropout2): QuantizedDropout(p=0.3, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): QuantizedLinear(in_features=25088, out_features=256, scale=3.241215229034424, zero_point=80, qscheme=torch.per_tensor_affine)\n",
              "  (fc2): QuantizedLinear(in_features=256, out_features=2, scale=0.7540537714958191, zero_point=53, qscheme=torch.per_tensor_affine)\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, looking at the statistics of various layers, we see that each convolutional layer and fully-connected layers have `scale` and `zero-point` values. Also it has become `QuantizedConv2d` for the convolutional layer and `QuantizedLinear` for the fully-connected layers."
      ],
      "metadata": {
        "id": "oV2TdraJWNZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights matrix of the model after quantization\n",
        "print('Weights after quantization')\n",
        "print(torch.int_repr(anantaJalilJr.conv1.weight()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGFJ9OFqQ3BW",
        "outputId": "9f4ad8b5-2616-4f67-fa16-8d2d0399e913"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after quantization\n",
            "tensor([[[[ -82,  -77,   83],\n",
            "          [ -19,   23,   83],\n",
            "          [ -22,  -18,  112]],\n",
            "\n",
            "         [[ -25,  -30,  -43],\n",
            "          [  -6,  -55,   21],\n",
            "          [ -14,  -11,  106]],\n",
            "\n",
            "         [[ -75,   27,   35],\n",
            "          [  18,  -81,  -55],\n",
            "          [ -24,   67,  -67]]],\n",
            "\n",
            "\n",
            "        [[[  26,   16,  -81],\n",
            "          [  93,   -2,  -31],\n",
            "          [  11,  -18,   85]],\n",
            "\n",
            "         [[ 103,  -63,  -95],\n",
            "          [ -26,  -88,   33],\n",
            "          [  89,   -8,   31]],\n",
            "\n",
            "         [[  -5,  -20,   13],\n",
            "          [ 104,   -7,   52],\n",
            "          [-102,   29,  -86]]],\n",
            "\n",
            "\n",
            "        [[[  71,  -19,  -46],\n",
            "          [  81,  -14,   25],\n",
            "          [  -9, -104,  -39]],\n",
            "\n",
            "         [[  87,  -95,    2],\n",
            "          [  70,  -71,  -15],\n",
            "          [  46,   37,   84]],\n",
            "\n",
            "         [[ -77,   44,   19],\n",
            "          [  -8,   55,   20],\n",
            "          [  66,  -15,  -90]]],\n",
            "\n",
            "\n",
            "        [[[   6,   75,   43],\n",
            "          [ -99,  -92,   12],\n",
            "          [ -95,  -86,  -54]],\n",
            "\n",
            "         [[ -32,  -56,   71],\n",
            "          [ -42,  -30,   21],\n",
            "          [ -45,  -14,  101]],\n",
            "\n",
            "         [[  17,   95, -108],\n",
            "          [  -5,   98,   90],\n",
            "          [ -21,  -87,  -70]]],\n",
            "\n",
            "\n",
            "        [[[  39,  -53,  -97],\n",
            "          [ -11,  -83,   19],\n",
            "          [ 107,   94,    4]],\n",
            "\n",
            "         [[ -51,  -32,  -54],\n",
            "          [ -68,  -27,  -85],\n",
            "          [ -91,   74,  -84]],\n",
            "\n",
            "         [[ -21,  -43,  -38],\n",
            "          [  26,  -21,   45],\n",
            "          [  89,  -95,  -29]]],\n",
            "\n",
            "\n",
            "        [[[  95,   42,   14],\n",
            "          [ -69,   24,   51],\n",
            "          [ -26,  -42,  -15]],\n",
            "\n",
            "         [[ -30,   24,  108],\n",
            "          [ -34,  -41,   30],\n",
            "          [ -83,  -20,   51]],\n",
            "\n",
            "         [[ -38,   34,  -96],\n",
            "          [ -39,   54,   17],\n",
            "          [   6,  -64,  -43]]],\n",
            "\n",
            "\n",
            "        [[[ 109,   76,   22],\n",
            "          [ -80,   10,  -54],\n",
            "          [  21,   34,   67]],\n",
            "\n",
            "         [[  83,   25,   81],\n",
            "          [ -50,   32,   60],\n",
            "          [  75,  -71,   73]],\n",
            "\n",
            "         [[ -30,  -15,  -45],\n",
            "          [-105,    8,  -95],\n",
            "          [  17,  -20,   14]]],\n",
            "\n",
            "\n",
            "        [[[ -82,  -26,  -75],\n",
            "          [ -22,  -10,  -75],\n",
            "          [   5,  -14,   11]],\n",
            "\n",
            "         [[  -3,    8,   69],\n",
            "          [ -27,   99,   53],\n",
            "          [  42,   80,   10]],\n",
            "\n",
            "         [[   4,  -98,   22],\n",
            "          [  47, -101,  -26],\n",
            "          [ -38,  -46,   77]]],\n",
            "\n",
            "\n",
            "        [[[ -71,   90,  -12],\n",
            "          [-102,  -94,   65],\n",
            "          [  87,   72,   64]],\n",
            "\n",
            "         [[  82,  -63,  -25],\n",
            "          [  82,  -58,   -9],\n",
            "          [  96,   61,   -2]],\n",
            "\n",
            "         [[  24, -109,  -88],\n",
            "          [  56,   59,   12],\n",
            "          [  72,  -69,  -24]]],\n",
            "\n",
            "\n",
            "        [[[ 102,  -96,   72],\n",
            "          [ -30,   42,  -41],\n",
            "          [ -13,  -77,  -79]],\n",
            "\n",
            "         [[  47,    3,   57],\n",
            "          [  -7,   64,  -92],\n",
            "          [  90,  111,  -46]],\n",
            "\n",
            "         [[ 101,  127,   96],\n",
            "          [ -14,   87,   38],\n",
            "          [ -48,  -67,   60]]],\n",
            "\n",
            "\n",
            "        [[[  72, -101,  -29],\n",
            "          [ -94,   57,  -28],\n",
            "          [  59,   83,  -17]],\n",
            "\n",
            "         [[-100,   74,  101],\n",
            "          [ -42,  -17,  -10],\n",
            "          [  38,  -69,   51]],\n",
            "\n",
            "         [[ -74,  -71,   -9],\n",
            "          [  24,   20,  -32],\n",
            "          [  55,   26,  -27]]],\n",
            "\n",
            "\n",
            "        [[[  23,   68,  -60],\n",
            "          [ -52,   56,   94],\n",
            "          [  35,  -93,    8]],\n",
            "\n",
            "         [[ -85,    3,  -29],\n",
            "          [ -98,  100,   78],\n",
            "          [  22,  -88,    3]],\n",
            "\n",
            "         [[ -11,   11,  -54],\n",
            "          [  56,  -60,   43],\n",
            "          [  44,   -7,   46]]],\n",
            "\n",
            "\n",
            "        [[[ -22,   91,  -81],\n",
            "          [ -73,  -30, -100],\n",
            "          [  83,   73,   73]],\n",
            "\n",
            "         [[  85,    6,  -17],\n",
            "          [  35,   84,   68],\n",
            "          [  53,  -48,  -44]],\n",
            "\n",
            "         [[  97,  -82,   39],\n",
            "          [  43,   79,    2],\n",
            "          [   1,  -80, -109]]],\n",
            "\n",
            "\n",
            "        [[[  94,  -57,  -84],\n",
            "          [   4,  -96,   -3],\n",
            "          [  27,  -78,   32]],\n",
            "\n",
            "         [[  90,  -89,   -7],\n",
            "          [  62,   73,   19],\n",
            "          [  33,    4,  -26]],\n",
            "\n",
            "         [[  55,  -33,  -19],\n",
            "          [ -93,  -89,   50],\n",
            "          [  48,    6,    0]]],\n",
            "\n",
            "\n",
            "        [[[ -85,   11,  -13],\n",
            "          [ -86,  -63,  -98],\n",
            "          [  97,   46,   78]],\n",
            "\n",
            "         [[ -44,  -67,   41],\n",
            "          [  55,   50,  -58],\n",
            "          [ -22,  -70,  -93]],\n",
            "\n",
            "         [[  26,   28,  -28],\n",
            "          [  38, -108,   50],\n",
            "          [ -97,   -2,  -67]]],\n",
            "\n",
            "\n",
            "        [[[  99,   68,  -28],\n",
            "          [  45,   63,  -26],\n",
            "          [  35,   -7,   24]],\n",
            "\n",
            "         [[ -62,  -35, -110],\n",
            "          [  99,    5,   49],\n",
            "          [ -38,   75,   30]],\n",
            "\n",
            "         [[ -16,  -87,   -2],\n",
            "          [  78,   59,  -92],\n",
            "          [ -60, -103,  -96]]],\n",
            "\n",
            "\n",
            "        [[[  36, -102,  -55],\n",
            "          [ -16,  -37,  -74],\n",
            "          [   1,   44,   93]],\n",
            "\n",
            "         [[ -22,   33,   12],\n",
            "          [  81,  101,    4],\n",
            "          [  -7,   53,   20]],\n",
            "\n",
            "         [[  30,   56,  -47],\n",
            "          [  66,  -81,  -63],\n",
            "          [  73,  -32,  -76]]],\n",
            "\n",
            "\n",
            "        [[[  14,  -74,   73],\n",
            "          [ -32,  -77,  -50],\n",
            "          [   5,   -1,   85]],\n",
            "\n",
            "         [[  39,  -92,  -27],\n",
            "          [ -17,   73,   -4],\n",
            "          [  50,  -96,   50]],\n",
            "\n",
            "         [[  -1,   32,   32],\n",
            "          [ -43,  -86,   23],\n",
            "          [  25, -114,  -33]]],\n",
            "\n",
            "\n",
            "        [[[ -19,   39, -109],\n",
            "          [ -21,   79, -116],\n",
            "          [ -46,   79,   70]],\n",
            "\n",
            "         [[ 103,   96,  -83],\n",
            "          [  92,   26, -109],\n",
            "          [ 102,   58,   36]],\n",
            "\n",
            "         [[ -93, -115, -104],\n",
            "          [  88,   13,   37],\n",
            "          [  -5,   90,   -3]]],\n",
            "\n",
            "\n",
            "        [[[ -24,  -54,   67],\n",
            "          [  87,  -80,    2],\n",
            "          [   8,  -87,  106]],\n",
            "\n",
            "         [[ -58,  -46,  -91],\n",
            "          [ -42,  -90,  -42],\n",
            "          [ -84, -104,   49]],\n",
            "\n",
            "         [[  -8,   53,  -84],\n",
            "          [ -81,  -22,  -12],\n",
            "          [  -9,   -4,   69]]],\n",
            "\n",
            "\n",
            "        [[[ -78,  -89,   25],\n",
            "          [ -73,   93,   -2],\n",
            "          [ 104,   97,  -37]],\n",
            "\n",
            "         [[  66,  -56,   22],\n",
            "          [  50,  -44,  -25],\n",
            "          [ -20,   66,  -29]],\n",
            "\n",
            "         [[ -27,  -78,    1],\n",
            "          [  44, -101,   53],\n",
            "          [  63,   56,  -83]]],\n",
            "\n",
            "\n",
            "        [[[  97,   49,   74],\n",
            "          [  61,   52,   29],\n",
            "          [ -19,   38,  -15]],\n",
            "\n",
            "         [[  13,   14,  -28],\n",
            "          [-109,  -35,   -7],\n",
            "          [  89,  -54,   76]],\n",
            "\n",
            "         [[  55,   18,  -29],\n",
            "          [  37,  -55,   55],\n",
            "          [ -53,  -76,    1]]],\n",
            "\n",
            "\n",
            "        [[[  17,   24,   83],\n",
            "          [ -24,  -13,  -45],\n",
            "          [ -36,   56,   -9]],\n",
            "\n",
            "         [[ -49,   68,  -24],\n",
            "          [ -26,    3, -107],\n",
            "          [  99,  -45,   61]],\n",
            "\n",
            "         [[  24,   -7,   42],\n",
            "          [ -96,  -67,  -31],\n",
            "          [ -73,   11,   71]]],\n",
            "\n",
            "\n",
            "        [[[ 107,  -73,    9],\n",
            "          [  93,  -54,  -21],\n",
            "          [ -43,  -88,   75]],\n",
            "\n",
            "         [[  94,  -54,  -88],\n",
            "          [ -20,  -12,   42],\n",
            "          [  -1,   22,   84]],\n",
            "\n",
            "         [[ -80,  -94,  -27],\n",
            "          [  50,  -39,   91],\n",
            "          [  28,   52,   67]]],\n",
            "\n",
            "\n",
            "        [[[ -84,  -31,   60],\n",
            "          [ -29,  -18,  -47],\n",
            "          [ 106,  -48,  -77]],\n",
            "\n",
            "         [[  65,   20,  -27],\n",
            "          [ 102,  -15,  -68],\n",
            "          [   5,   -6,    9]],\n",
            "\n",
            "         [[  76,   99,    3],\n",
            "          [  86,  -80,  -15],\n",
            "          [ -14,  -14,  -58]]],\n",
            "\n",
            "\n",
            "        [[[ -32,   22,   60],\n",
            "          [ -24,  107,  -40],\n",
            "          [ -17,  -11,  -59]],\n",
            "\n",
            "         [[  99,  108,    7],\n",
            "          [  -7,   76,  -59],\n",
            "          [  -2,   66,  -61]],\n",
            "\n",
            "         [[  67,   61,   65],\n",
            "          [ -25,  -14,   10],\n",
            "          [  68,   47,    9]]],\n",
            "\n",
            "\n",
            "        [[[  37,  -26,   97],\n",
            "          [  87,  -14,    6],\n",
            "          [  43,   22, -109]],\n",
            "\n",
            "         [[ -19,    7,  -21],\n",
            "          [  13,  -24,   58],\n",
            "          [  -7,  -79,   16]],\n",
            "\n",
            "         [[ -44,   46,   86],\n",
            "          [ -46,   15,  -51],\n",
            "          [  12,  -71,   -2]]],\n",
            "\n",
            "\n",
            "        [[[  67, -104,  -70],\n",
            "          [ 102,   13,   86],\n",
            "          [  -8,  -60,  -87]],\n",
            "\n",
            "         [[ -98,  -56,   20],\n",
            "          [  40,  -27,  -99],\n",
            "          [  82,  -81,   48]],\n",
            "\n",
            "         [[   3,   77,  108],\n",
            "          [  99,   43,   68],\n",
            "          [ -68,    5,  105]]],\n",
            "\n",
            "\n",
            "        [[[ -25,   64,   56],\n",
            "          [ -74,   97,   80],\n",
            "          [ -85,  -54,  -41]],\n",
            "\n",
            "         [[  17,  -47,  -55],\n",
            "          [ -11,    9,   -9],\n",
            "          [ -59,  111, -104]],\n",
            "\n",
            "         [[  43,  -18,   47],\n",
            "          [ -63,  -37,   90],\n",
            "          [  97,   64,  -90]]],\n",
            "\n",
            "\n",
            "        [[[  70,  -94,  -50],\n",
            "          [ -26,  103,  -50],\n",
            "          [   5,  -51,   50]],\n",
            "\n",
            "         [[ -57,  -94,   84],\n",
            "          [ -62,   69,   56],\n",
            "          [  50,  -32,  106]],\n",
            "\n",
            "         [[  89,  -38,   84],\n",
            "          [ -86,   28,   23],\n",
            "          [ -54,  -73,  -22]]],\n",
            "\n",
            "\n",
            "        [[[  97,  -18,   46],\n",
            "          [ -46,  -54,   70],\n",
            "          [  25,  -84,   23]],\n",
            "\n",
            "         [[  16,  112,  -54],\n",
            "          [  62,   25,   -7],\n",
            "          [ -10,   64,  -36]],\n",
            "\n",
            "         [[ -31,  114,   15],\n",
            "          [  81,  -81,   53],\n",
            "          [ -20,   32,  -56]]],\n",
            "\n",
            "\n",
            "        [[[ -62,   67,   53],\n",
            "          [ -22,   55, -104],\n",
            "          [  67,  107,  -80]],\n",
            "\n",
            "         [[  55, -111,   10],\n",
            "          [  33,  -56,  -62],\n",
            "          [ -74,   39,   51]],\n",
            "\n",
            "         [[  10,  -96,   88],\n",
            "          [ -80,   28,   44],\n",
            "          [ -16,    5,  -59]]]], dtype=torch.int8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the weights of first convolutional layer we see that due to quantization it has now been converted to `int8`."
      ],
      "metadata": {
        "id": "xGPijoUVWvg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As far as I know, while running the quantized model, it will run the weights in `float32` although it will store it in `int8` which will reduce the size. Thus, while testing the quantized model, we will see the dequantized `float32` weights from the `int8` weights."
      ],
      "metadata": {
        "id": "Yhfxwp7SXjyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original weights: ')\n",
        "print(anantaJalil.conv1.weight)\n",
        "print('')\n",
        "print(f'Dequantized weights: ')\n",
        "print(torch.dequantize(anantaJalilJr.conv1.weight()))\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szjKqSaYQ9VA",
        "outputId": "3e2779df-7852-4eaa-9336-bd587f698c76"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weights: \n",
            "Parameter containing:\n",
            "tensor([[[[-1.4485e-01, -1.3680e-01,  1.4645e-01],\n",
            "          [-3.4057e-02,  4.0066e-02,  1.4653e-01],\n",
            "          [-3.9360e-02, -3.1954e-02,  1.9848e-01]],\n",
            "\n",
            "         [[-4.3736e-02, -5.3364e-02, -7.6015e-02],\n",
            "          [-1.1375e-02, -9.7157e-02,  3.7182e-02],\n",
            "          [-2.4842e-02, -1.9482e-02,  1.8802e-01]],\n",
            "\n",
            "         [[-1.3220e-01,  4.8379e-02,  6.2325e-02],\n",
            "          [ 3.2245e-02, -1.4307e-01, -9.6930e-02],\n",
            "          [-4.3221e-02,  1.1859e-01, -1.1901e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6476e-02,  2.8481e-02, -1.4417e-01],\n",
            "          [ 1.6459e-01, -4.2325e-03, -5.4186e-02],\n",
            "          [ 1.9815e-02, -3.2094e-02,  1.5083e-01]],\n",
            "\n",
            "         [[ 1.8349e-01, -1.1144e-01, -1.6888e-01],\n",
            "          [-4.6052e-02, -1.5621e-01,  5.9176e-02],\n",
            "          [ 1.5712e-01, -1.4579e-02,  5.5457e-02]],\n",
            "\n",
            "         [[-8.7788e-03, -3.6236e-02,  2.2953e-02],\n",
            "          [ 1.8419e-01, -1.1851e-02,  9.2437e-02],\n",
            "          [-1.8030e-01,  5.1614e-02, -1.5324e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2613e-01, -3.3005e-02, -8.1910e-02],\n",
            "          [ 1.4338e-01, -2.5556e-02,  4.4361e-02],\n",
            "          [-1.5235e-02, -1.8513e-01, -6.9536e-02]],\n",
            "\n",
            "         [[ 1.5507e-01, -1.6935e-01,  3.4482e-03],\n",
            "          [ 1.2493e-01, -1.2673e-01, -2.5969e-02],\n",
            "          [ 8.1320e-02,  6.6221e-02,  1.4886e-01]],\n",
            "\n",
            "         [[-1.3599e-01,  7.7980e-02,  3.2938e-02],\n",
            "          [-1.4949e-02,  9.8223e-02,  3.5851e-02],\n",
            "          [ 1.1748e-01, -2.6009e-02, -1.5931e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0583e-02,  1.3259e-01,  7.6627e-02],\n",
            "          [-1.7558e-01, -1.6236e-01,  2.1227e-02],\n",
            "          [-1.6846e-01, -1.5338e-01, -9.5833e-02]],\n",
            "\n",
            "         [[-5.7477e-02, -9.9511e-02,  1.2672e-01],\n",
            "          [-7.4501e-02, -5.3230e-02,  3.6593e-02],\n",
            "          [-7.9914e-02, -2.5290e-02,  1.7934e-01]],\n",
            "\n",
            "         [[ 3.0984e-02,  1.6819e-01, -1.9126e-01],\n",
            "          [-8.7600e-03,  1.7447e-01,  1.5938e-01],\n",
            "          [-3.7053e-02, -1.5508e-01, -1.2381e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.9472e-02, -9.3301e-02, -1.7153e-01],\n",
            "          [-2.0297e-02, -1.4636e-01,  3.3298e-02],\n",
            "          [ 1.8910e-01,  1.6683e-01,  7.0740e-03]],\n",
            "\n",
            "         [[-8.9702e-02, -5.7498e-02, -9.6235e-02],\n",
            "          [-1.2082e-01, -4.8384e-02, -1.5011e-01],\n",
            "          [-1.6119e-01,  1.3172e-01, -1.4941e-01]],\n",
            "\n",
            "         [[-3.7335e-02, -7.5899e-02, -6.7303e-02],\n",
            "          [ 4.6689e-02, -3.8075e-02,  8.0344e-02],\n",
            "          [ 1.5727e-01, -1.6785e-01, -5.0822e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6822e-01,  7.5057e-02,  2.5015e-02],\n",
            "          [-1.2289e-01,  4.1975e-02,  9.0186e-02],\n",
            "          [-4.6694e-02, -7.4410e-02, -2.6818e-02]],\n",
            "\n",
            "         [[-5.3251e-02,  4.3260e-02,  1.9090e-01],\n",
            "          [-5.9722e-02, -7.2373e-02,  5.3751e-02],\n",
            "          [-1.4732e-01, -3.5794e-02,  9.1206e-02]],\n",
            "\n",
            "         [[-6.6974e-02,  6.0085e-02, -1.7008e-01],\n",
            "          [-6.8811e-02,  9.5998e-02,  3.0285e-02],\n",
            "          [ 1.1319e-02, -1.1347e-01, -7.5955e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9287e-01,  1.3447e-01,  3.9816e-02],\n",
            "          [-1.4233e-01,  1.6953e-02, -9.6035e-02],\n",
            "          [ 3.6781e-02,  5.9506e-02,  1.1930e-01]],\n",
            "\n",
            "         [[ 1.4667e-01,  4.3919e-02,  1.4326e-01],\n",
            "          [-8.8140e-02,  5.6622e-02,  1.0691e-01],\n",
            "          [ 1.3256e-01, -1.2601e-01,  1.3004e-01]],\n",
            "\n",
            "         [[-5.3154e-02, -2.7076e-02, -7.9651e-02],\n",
            "          [-1.8565e-01,  1.3548e-02, -1.6880e-01],\n",
            "          [ 2.9835e-02, -3.5791e-02,  2.5176e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4619e-01, -4.5575e-02, -1.3228e-01],\n",
            "          [-3.9495e-02, -1.8305e-02, -1.3342e-01],\n",
            "          [ 9.5899e-03, -2.5378e-02,  1.9978e-02]],\n",
            "\n",
            "         [[-5.5488e-03,  1.4521e-02,  1.2180e-01],\n",
            "          [-4.7447e-02,  1.7493e-01,  9.3101e-02],\n",
            "          [ 7.4086e-02,  1.4242e-01,  1.7132e-02]],\n",
            "\n",
            "         [[ 6.2495e-03, -1.7456e-01,  3.8641e-02],\n",
            "          [ 8.3534e-02, -1.7961e-01, -4.6430e-02],\n",
            "          [-6.7593e-02, -8.0758e-02,  1.3607e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.2535e-01,  1.5905e-01, -2.0422e-02],\n",
            "          [-1.8040e-01, -1.6615e-01,  1.1564e-01],\n",
            "          [ 1.5439e-01,  1.2831e-01,  1.1382e-01]],\n",
            "\n",
            "         [[ 1.4497e-01, -1.1162e-01, -4.4659e-02],\n",
            "          [ 1.4535e-01, -1.0308e-01, -1.5973e-02],\n",
            "          [ 1.6951e-01,  1.0802e-01, -2.8194e-03]],\n",
            "\n",
            "         [[ 4.1831e-02, -1.9410e-01, -1.5654e-01],\n",
            "          [ 9.9299e-02,  1.0513e-01,  2.0982e-02],\n",
            "          [ 1.2772e-01, -1.2188e-01, -4.2360e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8148e-01, -1.7077e-01,  1.2820e-01],\n",
            "          [-5.2389e-02,  7.4325e-02, -7.3267e-02],\n",
            "          [-2.3649e-02, -1.3725e-01, -1.4007e-01]],\n",
            "\n",
            "         [[ 8.3448e-02,  5.1999e-03,  1.0136e-01],\n",
            "          [-1.2541e-02,  1.1321e-01, -1.6334e-01],\n",
            "          [ 1.5902e-01,  1.9641e-01, -8.2208e-02]],\n",
            "\n",
            "         [[ 1.7930e-01,  2.2610e-01,  1.7081e-01],\n",
            "          [-2.5071e-02,  1.5448e-01,  6.8007e-02],\n",
            "          [-8.5555e-02, -1.1930e-01,  1.0719e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2714e-01, -1.7917e-01, -5.1065e-02],\n",
            "          [-1.6687e-01,  1.0116e-01, -5.0133e-02],\n",
            "          [ 1.0480e-01,  1.4754e-01, -3.0409e-02]],\n",
            "\n",
            "         [[-1.7671e-01,  1.3063e-01,  1.7858e-01],\n",
            "          [-7.5116e-02, -3.0969e-02, -1.7836e-02],\n",
            "          [ 6.7601e-02, -1.2187e-01,  9.0318e-02]],\n",
            "\n",
            "         [[-1.3102e-01, -1.2584e-01, -1.5889e-02],\n",
            "          [ 4.2682e-02,  3.6044e-02, -5.7148e-02],\n",
            "          [ 9.7968e-02,  4.6878e-02, -4.7948e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1628e-02,  1.2020e-01, -1.0686e-01],\n",
            "          [-9.2195e-02,  9.9905e-02,  1.6750e-01],\n",
            "          [ 6.2088e-02, -1.6510e-01,  1.3683e-02]],\n",
            "\n",
            "         [[-1.4993e-01,  5.3325e-03, -5.1759e-02],\n",
            "          [-1.7332e-01,  1.7692e-01,  1.3799e-01],\n",
            "          [ 3.8602e-02, -1.5619e-01,  5.3193e-03]],\n",
            "\n",
            "         [[-1.9360e-02,  1.9435e-02, -9.6184e-02],\n",
            "          [ 9.9001e-02, -1.0659e-01,  7.6359e-02],\n",
            "          [ 7.8005e-02, -1.2433e-02,  8.2324e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.8524e-02,  1.6077e-01, -1.4418e-01],\n",
            "          [-1.3015e-01, -5.2862e-02, -1.7723e-01],\n",
            "          [ 1.4648e-01,  1.3033e-01,  1.3013e-01]],\n",
            "\n",
            "         [[ 1.5112e-01,  9.9898e-03, -3.0170e-02],\n",
            "          [ 6.2113e-02,  1.4824e-01,  1.1992e-01],\n",
            "          [ 9.4598e-02, -8.5051e-02, -7.7513e-02]],\n",
            "\n",
            "         [[ 1.7257e-01, -1.4591e-01,  6.8492e-02],\n",
            "          [ 7.6674e-02,  1.4047e-01,  3.9104e-03],\n",
            "          [ 1.3672e-03, -1.4110e-01, -1.9417e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6638e-01, -1.0047e-01, -1.4973e-01],\n",
            "          [ 7.0262e-03, -1.6965e-01, -5.1625e-03],\n",
            "          [ 4.8121e-02, -1.3770e-01,  5.6439e-02]],\n",
            "\n",
            "         [[ 1.5952e-01, -1.5855e-01, -1.2996e-02],\n",
            "          [ 1.1018e-01,  1.2900e-01,  3.3385e-02],\n",
            "          [ 5.9115e-02,  7.5592e-03, -4.6909e-02]],\n",
            "\n",
            "         [[ 9.8112e-02, -5.8003e-02, -3.3492e-02],\n",
            "          [-1.6488e-01, -1.5715e-01,  8.8754e-02],\n",
            "          [ 8.5584e-02,  1.0991e-02,  1.4880e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.5029e-01,  1.9386e-02, -2.3835e-02],\n",
            "          [-1.5252e-01, -1.1194e-01, -1.7367e-01],\n",
            "          [ 1.7158e-01,  8.2248e-02,  1.3868e-01]],\n",
            "\n",
            "         [[-7.7342e-02, -1.1968e-01,  7.2613e-02],\n",
            "          [ 9.6840e-02,  8.9065e-02, -1.0274e-01],\n",
            "          [-3.9820e-02, -1.2344e-01, -1.6468e-01]],\n",
            "\n",
            "         [[ 4.6465e-02,  4.9369e-02, -4.9363e-02],\n",
            "          [ 6.8033e-02, -1.9082e-01,  8.8267e-02],\n",
            "          [-1.7230e-01, -3.7471e-03, -1.1836e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7500e-01,  1.2124e-01, -4.8858e-02],\n",
            "          [ 7.9623e-02,  1.1132e-01, -4.6138e-02],\n",
            "          [ 6.1731e-02, -1.2755e-02,  4.2113e-02]],\n",
            "\n",
            "         [[-1.0926e-01, -6.1210e-02, -1.9513e-01],\n",
            "          [ 1.7577e-01,  8.3555e-03,  8.6979e-02],\n",
            "          [-6.7091e-02,  1.3221e-01,  5.2917e-02]],\n",
            "\n",
            "         [[-2.8143e-02, -1.5441e-01, -3.5441e-03],\n",
            "          [ 1.3865e-01,  1.0547e-01, -1.6358e-01],\n",
            "          [-1.0678e-01, -1.8348e-01, -1.7093e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.4179e-02, -1.8018e-01, -9.7029e-02],\n",
            "          [-2.7487e-02, -6.5842e-02, -1.3170e-01],\n",
            "          [ 1.7317e-03,  7.8886e-02,  1.6478e-01]],\n",
            "\n",
            "         [[-3.9105e-02,  5.8046e-02,  2.2022e-02],\n",
            "          [ 1.4327e-01,  1.7895e-01,  7.4480e-03],\n",
            "          [-1.1772e-02,  9.3387e-02,  3.5594e-02]],\n",
            "\n",
            "         [[ 5.3443e-02,  9.8434e-02, -8.2614e-02],\n",
            "          [ 1.1791e-01, -1.4426e-01, -1.1112e-01],\n",
            "          [ 1.2976e-01, -5.6816e-02, -1.3488e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4422e-02, -1.3135e-01,  1.2964e-01],\n",
            "          [-5.6866e-02, -1.3596e-01, -8.8367e-02],\n",
            "          [ 8.8900e-03, -9.2596e-04,  1.5064e-01]],\n",
            "\n",
            "         [[ 6.8310e-02, -1.6290e-01, -4.8224e-02],\n",
            "          [-2.9538e-02,  1.2949e-01, -6.9709e-03],\n",
            "          [ 8.8054e-02, -1.7063e-01,  8.7938e-02]],\n",
            "\n",
            "         [[-2.1454e-03,  5.6964e-02,  5.6173e-02],\n",
            "          [-7.6995e-02, -1.5185e-01,  4.1270e-02],\n",
            "          [ 4.4791e-02, -2.0197e-01, -5.8808e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.3803e-02,  6.8878e-02, -1.9296e-01],\n",
            "          [-3.8059e-02,  1.3979e-01, -2.0515e-01],\n",
            "          [-8.1235e-02,  1.4063e-01,  1.2339e-01]],\n",
            "\n",
            "         [[ 1.8241e-01,  1.7051e-01, -1.4761e-01],\n",
            "          [ 1.6360e-01,  4.6031e-02, -1.9300e-01],\n",
            "          [ 1.8144e-01,  1.0320e-01,  6.3270e-02]],\n",
            "\n",
            "         [[-1.6577e-01, -2.0389e-01, -1.8418e-01],\n",
            "          [ 1.5598e-01,  2.3414e-02,  6.4942e-02],\n",
            "          [-8.8944e-03,  1.5898e-01, -5.0591e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.1817e-02, -9.5064e-02,  1.1920e-01],\n",
            "          [ 1.5451e-01, -1.4219e-01,  2.8562e-03],\n",
            "          [ 1.5059e-02, -1.5397e-01,  1.8882e-01]],\n",
            "\n",
            "         [[-1.0240e-01, -8.1835e-02, -1.6218e-01],\n",
            "          [-7.4627e-02, -1.6007e-01, -7.3918e-02],\n",
            "          [-1.4906e-01, -1.8383e-01,  8.6605e-02]],\n",
            "\n",
            "         [[-1.3993e-02,  9.4336e-02, -1.4924e-01],\n",
            "          [-1.4341e-01, -3.8623e-02, -2.1781e-02],\n",
            "          [-1.5374e-02, -7.8441e-03,  1.2155e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.3907e-01, -1.5740e-01,  4.5004e-02],\n",
            "          [-1.2888e-01,  1.6407e-01, -2.9501e-03],\n",
            "          [ 1.8381e-01,  1.7150e-01, -6.4922e-02]],\n",
            "\n",
            "         [[ 1.1789e-01, -9.9940e-02,  3.8157e-02],\n",
            "          [ 8.9214e-02, -7.8909e-02, -4.4064e-02],\n",
            "          [-3.5435e-02,  1.1716e-01, -5.1527e-02]],\n",
            "\n",
            "         [[-4.7707e-02, -1.3894e-01,  2.4521e-03],\n",
            "          [ 7.7687e-02, -1.7981e-01,  9.3259e-02],\n",
            "          [ 1.1106e-01,  1.0018e-01, -1.4732e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7184e-01,  8.7111e-02,  1.3187e-01],\n",
            "          [ 1.0801e-01,  9.2048e-02,  5.1726e-02],\n",
            "          [-3.2899e-02,  6.7387e-02, -2.6318e-02]],\n",
            "\n",
            "         [[ 2.3738e-02,  2.4617e-02, -5.0355e-02],\n",
            "          [-1.9379e-01, -6.2319e-02, -1.1678e-02],\n",
            "          [ 1.5735e-01, -9.5129e-02,  1.3452e-01]],\n",
            "\n",
            "         [[ 9.6816e-02,  3.1521e-02, -5.1935e-02],\n",
            "          [ 6.5460e-02, -9.8199e-02,  9.8186e-02],\n",
            "          [-9.4613e-02, -1.3513e-01,  1.9804e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9848e-02,  4.3293e-02,  1.4697e-01],\n",
            "          [-4.2260e-02, -2.2760e-02, -8.0040e-02],\n",
            "          [-6.4313e-02,  9.9457e-02, -1.5328e-02]],\n",
            "\n",
            "         [[-8.6401e-02,  1.2122e-01, -4.2462e-02],\n",
            "          [-4.6077e-02,  4.5522e-03, -1.8964e-01],\n",
            "          [ 1.7582e-01, -8.0537e-02,  1.0792e-01]],\n",
            "\n",
            "         [[ 4.3425e-02, -1.2915e-02,  7.4022e-02],\n",
            "          [-1.6969e-01, -1.1812e-01, -5.4931e-02],\n",
            "          [-1.2871e-01,  2.0057e-02,  1.2578e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9010e-01, -1.3011e-01,  1.5723e-02],\n",
            "          [ 1.6436e-01, -9.5573e-02, -3.6419e-02],\n",
            "          [-7.6545e-02, -1.5593e-01,  1.3378e-01]],\n",
            "\n",
            "         [[ 1.6735e-01, -9.4997e-02, -1.5566e-01],\n",
            "          [-3.6082e-02, -2.1546e-02,  7.4088e-02],\n",
            "          [-2.2543e-03,  3.9237e-02,  1.4824e-01]],\n",
            "\n",
            "         [[-1.4179e-01, -1.6659e-01, -4.7469e-02],\n",
            "          [ 8.9369e-02, -6.9953e-02,  1.6150e-01],\n",
            "          [ 5.0271e-02,  9.2768e-02,  1.1813e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4923e-01, -5.4112e-02,  1.0658e-01],\n",
            "          [-5.1818e-02, -3.1535e-02, -8.4230e-02],\n",
            "          [ 1.8770e-01, -8.5369e-02, -1.3622e-01]],\n",
            "\n",
            "         [[ 1.1575e-01,  3.6279e-02, -4.7278e-02],\n",
            "          [ 1.8044e-01, -2.6467e-02, -1.2014e-01],\n",
            "          [ 8.0620e-03, -1.1511e-02,  1.6318e-02]],\n",
            "\n",
            "         [[ 1.3416e-01,  1.7629e-01,  5.4557e-03],\n",
            "          [ 1.5314e-01, -1.4113e-01, -2.6760e-02],\n",
            "          [-2.5497e-02, -2.4365e-02, -1.0302e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.7513e-02,  3.8575e-02,  1.0656e-01],\n",
            "          [-4.2221e-02,  1.8947e-01, -7.0441e-02],\n",
            "          [-2.9824e-02, -2.0148e-02, -1.0547e-01]],\n",
            "\n",
            "         [[ 1.7514e-01,  1.9166e-01,  1.2173e-02],\n",
            "          [-1.2226e-02,  1.3446e-01, -1.0550e-01],\n",
            "          [-4.3547e-03,  1.1703e-01, -1.0803e-01]],\n",
            "\n",
            "         [[ 1.1865e-01,  1.0765e-01,  1.1505e-01],\n",
            "          [-4.4685e-02, -2.4972e-02,  1.7249e-02],\n",
            "          [ 1.1991e-01,  8.3728e-02,  1.5415e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6383e-02, -4.6928e-02,  1.7191e-01],\n",
            "          [ 1.5468e-01, -2.4082e-02,  1.0338e-02],\n",
            "          [ 7.5416e-02,  3.8180e-02, -1.9415e-01]],\n",
            "\n",
            "         [[-3.4266e-02,  1.1816e-02, -3.6417e-02],\n",
            "          [ 2.3780e-02, -4.2697e-02,  1.0335e-01],\n",
            "          [-1.2595e-02, -1.4068e-01,  2.9151e-02]],\n",
            "\n",
            "         [[-7.8301e-02,  8.1336e-02,  1.5198e-01],\n",
            "          [-8.0917e-02,  2.7422e-02, -8.9801e-02],\n",
            "          [ 2.0528e-02, -1.2649e-01, -4.3358e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1826e-01, -1.8517e-01, -1.2369e-01],\n",
            "          [ 1.8030e-01,  2.2952e-02,  1.5220e-01],\n",
            "          [-1.4264e-02, -1.0658e-01, -1.5433e-01]],\n",
            "\n",
            "         [[-1.7429e-01, -9.8733e-02,  3.4893e-02],\n",
            "          [ 7.0552e-02, -4.7045e-02, -1.7623e-01],\n",
            "          [ 1.4588e-01, -1.4324e-01,  8.4266e-02]],\n",
            "\n",
            "         [[ 5.5731e-03,  1.3650e-01,  1.9102e-01],\n",
            "          [ 1.7546e-01,  7.6116e-02,  1.2114e-01],\n",
            "          [-1.2064e-01,  9.7246e-03,  1.8688e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.5208e-02,  1.1376e-01,  9.9147e-02],\n",
            "          [-1.3112e-01,  1.7266e-01,  1.4257e-01],\n",
            "          [-1.5019e-01, -9.5405e-02, -7.1847e-02]],\n",
            "\n",
            "         [[ 2.9326e-02, -8.3908e-02, -9.7278e-02],\n",
            "          [-2.0065e-02,  1.5652e-02, -1.5911e-02],\n",
            "          [-1.0470e-01,  1.9761e-01, -1.8475e-01]],\n",
            "\n",
            "         [[ 7.5689e-02, -3.2021e-02,  8.3734e-02],\n",
            "          [-1.1155e-01, -6.5183e-02,  1.5887e-01],\n",
            "          [ 1.7209e-01,  1.1356e-01, -1.6012e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2413e-01, -1.6664e-01, -8.7784e-02],\n",
            "          [-4.6882e-02,  1.8333e-01, -8.9443e-02],\n",
            "          [ 8.5285e-03, -9.1295e-02,  8.9521e-02]],\n",
            "\n",
            "         [[-1.0026e-01, -1.6642e-01,  1.4948e-01],\n",
            "          [-1.1051e-01,  1.2226e-01,  9.9898e-02],\n",
            "          [ 8.9069e-02, -5.6319e-02,  1.8739e-01]],\n",
            "\n",
            "         [[ 1.5803e-01, -6.7815e-02,  1.4958e-01],\n",
            "          [-1.5273e-01,  4.9499e-02,  4.0154e-02],\n",
            "          [-9.4899e-02, -1.3024e-01, -3.9622e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7262e-01, -3.1516e-02,  8.1172e-02],\n",
            "          [-8.1405e-02, -9.6629e-02,  1.2381e-01],\n",
            "          [ 4.4744e-02, -1.4893e-01,  4.0342e-02]],\n",
            "\n",
            "         [[ 2.7545e-02,  1.9855e-01, -9.5450e-02],\n",
            "          [ 1.1038e-01,  4.4149e-02, -1.3244e-02],\n",
            "          [-1.7253e-02,  1.1431e-01, -6.4435e-02]],\n",
            "\n",
            "         [[-5.4794e-02,  2.0168e-01,  2.7400e-02],\n",
            "          [ 1.4295e-01, -1.4336e-01,  9.3635e-02],\n",
            "          [-3.6302e-02,  5.7583e-02, -9.9474e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.1058e-01,  1.1961e-01,  9.4726e-02],\n",
            "          [-3.8370e-02,  9.7232e-02, -1.8448e-01],\n",
            "          [ 1.1827e-01,  1.8993e-01, -1.4127e-01]],\n",
            "\n",
            "         [[ 9.7388e-02, -1.9692e-01,  1.6959e-02],\n",
            "          [ 5.8086e-02, -9.9747e-02, -1.0914e-01],\n",
            "          [-1.3209e-01,  6.9679e-02,  9.1267e-02]],\n",
            "\n",
            "         [[ 1.7849e-02, -1.7060e-01,  1.5654e-01],\n",
            "          [-1.4108e-01,  4.9143e-02,  7.8021e-02],\n",
            "          [-2.9095e-02,  8.7397e-03, -1.0404e-01]]]], requires_grad=True)\n",
            "\n",
            "Dequantized weights: \n",
            "tensor([[[[-0.1454, -0.1365,  0.1472],\n",
            "          [-0.0337,  0.0408,  0.1472],\n",
            "          [-0.0390, -0.0319,  0.1986]],\n",
            "\n",
            "         [[-0.0443, -0.0532, -0.0763],\n",
            "          [-0.0106, -0.0975,  0.0372],\n",
            "          [-0.0248, -0.0195,  0.1880]],\n",
            "\n",
            "         [[-0.1330,  0.0479,  0.0621],\n",
            "          [ 0.0319, -0.1436, -0.0975],\n",
            "          [-0.0426,  0.1188, -0.1188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0461,  0.0284, -0.1436],\n",
            "          [ 0.1649, -0.0035, -0.0550],\n",
            "          [ 0.0195, -0.0319,  0.1507]],\n",
            "\n",
            "         [[ 0.1827, -0.1117, -0.1685],\n",
            "          [-0.0461, -0.1561,  0.0585],\n",
            "          [ 0.1578, -0.0142,  0.0550]],\n",
            "\n",
            "         [[-0.0089, -0.0355,  0.0231],\n",
            "          [ 0.1844, -0.0124,  0.0922],\n",
            "          [-0.1809,  0.0514, -0.1525]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1259, -0.0337, -0.0816],\n",
            "          [ 0.1436, -0.0248,  0.0443],\n",
            "          [-0.0160, -0.1844, -0.0692]],\n",
            "\n",
            "         [[ 0.1543, -0.1685,  0.0035],\n",
            "          [ 0.1241, -0.1259, -0.0266],\n",
            "          [ 0.0816,  0.0656,  0.1490]],\n",
            "\n",
            "         [[-0.1365,  0.0780,  0.0337],\n",
            "          [-0.0142,  0.0975,  0.0355],\n",
            "          [ 0.1170, -0.0266, -0.1596]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0106,  0.1330,  0.0763],\n",
            "          [-0.1756, -0.1631,  0.0213],\n",
            "          [-0.1685, -0.1525, -0.0958]],\n",
            "\n",
            "         [[-0.0567, -0.0993,  0.1259],\n",
            "          [-0.0745, -0.0532,  0.0372],\n",
            "          [-0.0798, -0.0248,  0.1791]],\n",
            "\n",
            "         [[ 0.0301,  0.1685, -0.1915],\n",
            "          [-0.0089,  0.1738,  0.1596],\n",
            "          [-0.0372, -0.1543, -0.1241]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0692, -0.0940, -0.1720],\n",
            "          [-0.0195, -0.1472,  0.0337],\n",
            "          [ 0.1897,  0.1667,  0.0071]],\n",
            "\n",
            "         [[-0.0904, -0.0567, -0.0958],\n",
            "          [-0.1206, -0.0479, -0.1507],\n",
            "          [-0.1614,  0.1312, -0.1490]],\n",
            "\n",
            "         [[-0.0372, -0.0763, -0.0674],\n",
            "          [ 0.0461, -0.0372,  0.0798],\n",
            "          [ 0.1578, -0.1685, -0.0514]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1685,  0.0745,  0.0248],\n",
            "          [-0.1224,  0.0426,  0.0904],\n",
            "          [-0.0461, -0.0745, -0.0266]],\n",
            "\n",
            "         [[-0.0532,  0.0426,  0.1915],\n",
            "          [-0.0603, -0.0727,  0.0532],\n",
            "          [-0.1472, -0.0355,  0.0904]],\n",
            "\n",
            "         [[-0.0674,  0.0603, -0.1702],\n",
            "          [-0.0692,  0.0958,  0.0301],\n",
            "          [ 0.0106, -0.1135, -0.0763]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1933,  0.1348,  0.0390],\n",
            "          [-0.1419,  0.0177, -0.0958],\n",
            "          [ 0.0372,  0.0603,  0.1188]],\n",
            "\n",
            "         [[ 0.1472,  0.0443,  0.1436],\n",
            "          [-0.0887,  0.0567,  0.1064],\n",
            "          [ 0.1330, -0.1259,  0.1295]],\n",
            "\n",
            "         [[-0.0532, -0.0266, -0.0798],\n",
            "          [-0.1862,  0.0142, -0.1685],\n",
            "          [ 0.0301, -0.0355,  0.0248]]],\n",
            "\n",
            "\n",
            "        [[[-0.1454, -0.0461, -0.1330],\n",
            "          [-0.0390, -0.0177, -0.1330],\n",
            "          [ 0.0089, -0.0248,  0.0195]],\n",
            "\n",
            "         [[-0.0053,  0.0142,  0.1224],\n",
            "          [-0.0479,  0.1756,  0.0940],\n",
            "          [ 0.0745,  0.1419,  0.0177]],\n",
            "\n",
            "         [[ 0.0071, -0.1738,  0.0390],\n",
            "          [ 0.0833, -0.1791, -0.0461],\n",
            "          [-0.0674, -0.0816,  0.1365]]],\n",
            "\n",
            "\n",
            "        [[[-0.1259,  0.1596, -0.0213],\n",
            "          [-0.1809, -0.1667,  0.1153],\n",
            "          [ 0.1543,  0.1277,  0.1135]],\n",
            "\n",
            "         [[ 0.1454, -0.1117, -0.0443],\n",
            "          [ 0.1454, -0.1029, -0.0160],\n",
            "          [ 0.1702,  0.1082, -0.0035]],\n",
            "\n",
            "         [[ 0.0426, -0.1933, -0.1561],\n",
            "          [ 0.0993,  0.1046,  0.0213],\n",
            "          [ 0.1277, -0.1224, -0.0426]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1809, -0.1702,  0.1277],\n",
            "          [-0.0532,  0.0745, -0.0727],\n",
            "          [-0.0231, -0.1365, -0.1401]],\n",
            "\n",
            "         [[ 0.0833,  0.0053,  0.1011],\n",
            "          [-0.0124,  0.1135, -0.1631],\n",
            "          [ 0.1596,  0.1968, -0.0816]],\n",
            "\n",
            "         [[ 0.1791,  0.2252,  0.1702],\n",
            "          [-0.0248,  0.1543,  0.0674],\n",
            "          [-0.0851, -0.1188,  0.1064]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1277, -0.1791, -0.0514],\n",
            "          [-0.1667,  0.1011, -0.0497],\n",
            "          [ 0.1046,  0.1472, -0.0301]],\n",
            "\n",
            "         [[-0.1773,  0.1312,  0.1791],\n",
            "          [-0.0745, -0.0301, -0.0177],\n",
            "          [ 0.0674, -0.1224,  0.0904]],\n",
            "\n",
            "         [[-0.1312, -0.1259, -0.0160],\n",
            "          [ 0.0426,  0.0355, -0.0567],\n",
            "          [ 0.0975,  0.0461, -0.0479]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0408,  0.1206, -0.1064],\n",
            "          [-0.0922,  0.0993,  0.1667],\n",
            "          [ 0.0621, -0.1649,  0.0142]],\n",
            "\n",
            "         [[-0.1507,  0.0053, -0.0514],\n",
            "          [-0.1738,  0.1773,  0.1383],\n",
            "          [ 0.0390, -0.1561,  0.0053]],\n",
            "\n",
            "         [[-0.0195,  0.0195, -0.0958],\n",
            "          [ 0.0993, -0.1064,  0.0763],\n",
            "          [ 0.0780, -0.0124,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[-0.0390,  0.1614, -0.1436],\n",
            "          [-0.1295, -0.0532, -0.1773],\n",
            "          [ 0.1472,  0.1295,  0.1295]],\n",
            "\n",
            "         [[ 0.1507,  0.0106, -0.0301],\n",
            "          [ 0.0621,  0.1490,  0.1206],\n",
            "          [ 0.0940, -0.0851, -0.0780]],\n",
            "\n",
            "         [[ 0.1720, -0.1454,  0.0692],\n",
            "          [ 0.0763,  0.1401,  0.0035],\n",
            "          [ 0.0018, -0.1419, -0.1933]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1667, -0.1011, -0.1490],\n",
            "          [ 0.0071, -0.1702, -0.0053],\n",
            "          [ 0.0479, -0.1383,  0.0567]],\n",
            "\n",
            "         [[ 0.1596, -0.1578, -0.0124],\n",
            "          [ 0.1099,  0.1295,  0.0337],\n",
            "          [ 0.0585,  0.0071, -0.0461]],\n",
            "\n",
            "         [[ 0.0975, -0.0585, -0.0337],\n",
            "          [-0.1649, -0.1578,  0.0887],\n",
            "          [ 0.0851,  0.0106,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1507,  0.0195, -0.0231],\n",
            "          [-0.1525, -0.1117, -0.1738],\n",
            "          [ 0.1720,  0.0816,  0.1383]],\n",
            "\n",
            "         [[-0.0780, -0.1188,  0.0727],\n",
            "          [ 0.0975,  0.0887, -0.1029],\n",
            "          [-0.0390, -0.1241, -0.1649]],\n",
            "\n",
            "         [[ 0.0461,  0.0497, -0.0497],\n",
            "          [ 0.0674, -0.1915,  0.0887],\n",
            "          [-0.1720, -0.0035, -0.1188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1756,  0.1206, -0.0497],\n",
            "          [ 0.0798,  0.1117, -0.0461],\n",
            "          [ 0.0621, -0.0124,  0.0426]],\n",
            "\n",
            "         [[-0.1099, -0.0621, -0.1951],\n",
            "          [ 0.1756,  0.0089,  0.0869],\n",
            "          [-0.0674,  0.1330,  0.0532]],\n",
            "\n",
            "         [[-0.0284, -0.1543, -0.0035],\n",
            "          [ 0.1383,  0.1046, -0.1631],\n",
            "          [-0.1064, -0.1827, -0.1702]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0638, -0.1809, -0.0975],\n",
            "          [-0.0284, -0.0656, -0.1312],\n",
            "          [ 0.0018,  0.0780,  0.1649]],\n",
            "\n",
            "         [[-0.0390,  0.0585,  0.0213],\n",
            "          [ 0.1436,  0.1791,  0.0071],\n",
            "          [-0.0124,  0.0940,  0.0355]],\n",
            "\n",
            "         [[ 0.0532,  0.0993, -0.0833],\n",
            "          [ 0.1170, -0.1436, -0.1117],\n",
            "          [ 0.1295, -0.0567, -0.1348]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0248, -0.1312,  0.1295],\n",
            "          [-0.0567, -0.1365, -0.0887],\n",
            "          [ 0.0089, -0.0018,  0.1507]],\n",
            "\n",
            "         [[ 0.0692, -0.1631, -0.0479],\n",
            "          [-0.0301,  0.1295, -0.0071],\n",
            "          [ 0.0887, -0.1702,  0.0887]],\n",
            "\n",
            "         [[-0.0018,  0.0567,  0.0567],\n",
            "          [-0.0763, -0.1525,  0.0408],\n",
            "          [ 0.0443, -0.2022, -0.0585]]],\n",
            "\n",
            "\n",
            "        [[[-0.0337,  0.0692, -0.1933],\n",
            "          [-0.0372,  0.1401, -0.2057],\n",
            "          [-0.0816,  0.1401,  0.1241]],\n",
            "\n",
            "         [[ 0.1827,  0.1702, -0.1472],\n",
            "          [ 0.1631,  0.0461, -0.1933],\n",
            "          [ 0.1809,  0.1029,  0.0638]],\n",
            "\n",
            "         [[-0.1649, -0.2039, -0.1844],\n",
            "          [ 0.1561,  0.0231,  0.0656],\n",
            "          [-0.0089,  0.1596, -0.0053]]],\n",
            "\n",
            "\n",
            "        [[[-0.0426, -0.0958,  0.1188],\n",
            "          [ 0.1543, -0.1419,  0.0035],\n",
            "          [ 0.0142, -0.1543,  0.1880]],\n",
            "\n",
            "         [[-0.1029, -0.0816, -0.1614],\n",
            "          [-0.0745, -0.1596, -0.0745],\n",
            "          [-0.1490, -0.1844,  0.0869]],\n",
            "\n",
            "         [[-0.0142,  0.0940, -0.1490],\n",
            "          [-0.1436, -0.0390, -0.0213],\n",
            "          [-0.0160, -0.0071,  0.1224]]],\n",
            "\n",
            "\n",
            "        [[[-0.1383, -0.1578,  0.0443],\n",
            "          [-0.1295,  0.1649, -0.0035],\n",
            "          [ 0.1844,  0.1720, -0.0656]],\n",
            "\n",
            "         [[ 0.1170, -0.0993,  0.0390],\n",
            "          [ 0.0887, -0.0780, -0.0443],\n",
            "          [-0.0355,  0.1170, -0.0514]],\n",
            "\n",
            "         [[-0.0479, -0.1383,  0.0018],\n",
            "          [ 0.0780, -0.1791,  0.0940],\n",
            "          [ 0.1117,  0.0993, -0.1472]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1720,  0.0869,  0.1312],\n",
            "          [ 0.1082,  0.0922,  0.0514],\n",
            "          [-0.0337,  0.0674, -0.0266]],\n",
            "\n",
            "         [[ 0.0231,  0.0248, -0.0497],\n",
            "          [-0.1933, -0.0621, -0.0124],\n",
            "          [ 0.1578, -0.0958,  0.1348]],\n",
            "\n",
            "         [[ 0.0975,  0.0319, -0.0514],\n",
            "          [ 0.0656, -0.0975,  0.0975],\n",
            "          [-0.0940, -0.1348,  0.0018]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0301,  0.0426,  0.1472],\n",
            "          [-0.0426, -0.0231, -0.0798],\n",
            "          [-0.0638,  0.0993, -0.0160]],\n",
            "\n",
            "         [[-0.0869,  0.1206, -0.0426],\n",
            "          [-0.0461,  0.0053, -0.1897],\n",
            "          [ 0.1756, -0.0798,  0.1082]],\n",
            "\n",
            "         [[ 0.0426, -0.0124,  0.0745],\n",
            "          [-0.1702, -0.1188, -0.0550],\n",
            "          [-0.1295,  0.0195,  0.1259]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1897, -0.1295,  0.0160],\n",
            "          [ 0.1649, -0.0958, -0.0372],\n",
            "          [-0.0763, -0.1561,  0.1330]],\n",
            "\n",
            "         [[ 0.1667, -0.0958, -0.1561],\n",
            "          [-0.0355, -0.0213,  0.0745],\n",
            "          [-0.0018,  0.0390,  0.1490]],\n",
            "\n",
            "         [[-0.1419, -0.1667, -0.0479],\n",
            "          [ 0.0887, -0.0692,  0.1614],\n",
            "          [ 0.0497,  0.0922,  0.1188]]],\n",
            "\n",
            "\n",
            "        [[[-0.1490, -0.0550,  0.1064],\n",
            "          [-0.0514, -0.0319, -0.0833],\n",
            "          [ 0.1880, -0.0851, -0.1365]],\n",
            "\n",
            "         [[ 0.1153,  0.0355, -0.0479],\n",
            "          [ 0.1809, -0.0266, -0.1206],\n",
            "          [ 0.0089, -0.0106,  0.0160]],\n",
            "\n",
            "         [[ 0.1348,  0.1756,  0.0053],\n",
            "          [ 0.1525, -0.1419, -0.0266],\n",
            "          [-0.0248, -0.0248, -0.1029]]],\n",
            "\n",
            "\n",
            "        [[[-0.0567,  0.0390,  0.1064],\n",
            "          [-0.0426,  0.1897, -0.0709],\n",
            "          [-0.0301, -0.0195, -0.1046]],\n",
            "\n",
            "         [[ 0.1756,  0.1915,  0.0124],\n",
            "          [-0.0124,  0.1348, -0.1046],\n",
            "          [-0.0035,  0.1170, -0.1082]],\n",
            "\n",
            "         [[ 0.1188,  0.1082,  0.1153],\n",
            "          [-0.0443, -0.0248,  0.0177],\n",
            "          [ 0.1206,  0.0833,  0.0160]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0656, -0.0461,  0.1720],\n",
            "          [ 0.1543, -0.0248,  0.0106],\n",
            "          [ 0.0763,  0.0390, -0.1933]],\n",
            "\n",
            "         [[-0.0337,  0.0124, -0.0372],\n",
            "          [ 0.0231, -0.0426,  0.1029],\n",
            "          [-0.0124, -0.1401,  0.0284]],\n",
            "\n",
            "         [[-0.0780,  0.0816,  0.1525],\n",
            "          [-0.0816,  0.0266, -0.0904],\n",
            "          [ 0.0213, -0.1259, -0.0035]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1188, -0.1844, -0.1241],\n",
            "          [ 0.1809,  0.0231,  0.1525],\n",
            "          [-0.0142, -0.1064, -0.1543]],\n",
            "\n",
            "         [[-0.1738, -0.0993,  0.0355],\n",
            "          [ 0.0709, -0.0479, -0.1756],\n",
            "          [ 0.1454, -0.1436,  0.0851]],\n",
            "\n",
            "         [[ 0.0053,  0.1365,  0.1915],\n",
            "          [ 0.1756,  0.0763,  0.1206],\n",
            "          [-0.1206,  0.0089,  0.1862]]],\n",
            "\n",
            "\n",
            "        [[[-0.0443,  0.1135,  0.0993],\n",
            "          [-0.1312,  0.1720,  0.1419],\n",
            "          [-0.1507, -0.0958, -0.0727]],\n",
            "\n",
            "         [[ 0.0301, -0.0833, -0.0975],\n",
            "          [-0.0195,  0.0160, -0.0160],\n",
            "          [-0.1046,  0.1968, -0.1844]],\n",
            "\n",
            "         [[ 0.0763, -0.0319,  0.0833],\n",
            "          [-0.1117, -0.0656,  0.1596],\n",
            "          [ 0.1720,  0.1135, -0.1596]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1241, -0.1667, -0.0887],\n",
            "          [-0.0461,  0.1827, -0.0887],\n",
            "          [ 0.0089, -0.0904,  0.0887]],\n",
            "\n",
            "         [[-0.1011, -0.1667,  0.1490],\n",
            "          [-0.1099,  0.1224,  0.0993],\n",
            "          [ 0.0887, -0.0567,  0.1880]],\n",
            "\n",
            "         [[ 0.1578, -0.0674,  0.1490],\n",
            "          [-0.1525,  0.0497,  0.0408],\n",
            "          [-0.0958, -0.1295, -0.0390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1720, -0.0319,  0.0816],\n",
            "          [-0.0816, -0.0958,  0.1241],\n",
            "          [ 0.0443, -0.1490,  0.0408]],\n",
            "\n",
            "         [[ 0.0284,  0.1986, -0.0958],\n",
            "          [ 0.1099,  0.0443, -0.0124],\n",
            "          [-0.0177,  0.1135, -0.0638]],\n",
            "\n",
            "         [[-0.0550,  0.2022,  0.0266],\n",
            "          [ 0.1436, -0.1436,  0.0940],\n",
            "          [-0.0355,  0.0567, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[-0.1099,  0.1188,  0.0940],\n",
            "          [-0.0390,  0.0975, -0.1844],\n",
            "          [ 0.1188,  0.1897, -0.1419]],\n",
            "\n",
            "         [[ 0.0975, -0.1968,  0.0177],\n",
            "          [ 0.0585, -0.0993, -0.1099],\n",
            "          [-0.1312,  0.0692,  0.0904]],\n",
            "\n",
            "         [[ 0.0177, -0.1702,  0.1561],\n",
            "          [-0.1419,  0.0497,  0.0780],\n",
            "          [-0.0284,  0.0089, -0.1046]]]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, we see the weights of the original model versus the dequantized weights of the quantized model (converted from `int8` to `float32`) remains almost similiar."
      ],
      "metadata": {
        "id": "8BJRk73nX9hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of the model after quantization')\n",
        "print_size_of_model(anantaJalilJr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au-PFlgzRFuR",
        "outputId": "baaf88fa-181b-4ab1-9e8a-b73d8e8ae271"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model after quantization\n",
            "Size (MB): 8.031906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Testing the model after quantization')\n",
        "test(anantaJalilJr, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq0BK0DuROP8",
        "outputId": "f3625ff7-63ce-4ba0-a9ee-fe65c4af8042"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [00:42<00:00,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.973015873015873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So finally, we see that the size of the quantized model is 8.03MB which is about 4x smaller than the original model which sized 31.99MB! Also we see the accuracy has not dropped significantly."
      ],
      "metadata": {
        "id": "i4_Z0jEAYRTK"
      }
    }
  ]
}